{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Sample GeoAI Wrapper for Clay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geoai.clay import Clay\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clay_model = Clay(sensor_name=\"sentinel-2-l2a\")\n",
    "clay_model.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.rand((256, 256, 10))\n",
    "embedding = clay_model.generate(t1)\n",
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'stackstac[viz]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pystac_client\n",
    "import stackstac\n",
    "from shapely import Point\n",
    "from rasterio.enums import Resampling\n",
    "import torch\n",
    "import yaml\n",
    "from box import Box\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn import decomposition, svm\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from claymodel.module import ClayMAEModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point over Monchique Portugal\n",
    "lat, lon = 37.30939, -8.57207\n",
    "\n",
    "# Dates of a large forest fire\n",
    "start = \"2018-07-01\"\n",
    "end = \"2018-09-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "STAC_API = \"https://earth-search.aws.element84.com/v1\"\n",
    "COLLECTION = \"sentinel-2-l2a\"\n",
    "\n",
    "# Search the catalogue\n",
    "catalog = pystac_client.Client.open(STAC_API)\n",
    "search = catalog.search(\n",
    "    collections=[COLLECTION],\n",
    "    datetime=f\"{start}/{end}\",\n",
    "    bbox=(lon - 1e-5, lat - 1e-5, lon + 1e-5, lat + 1e-5),\n",
    "    max_items=100,\n",
    "    query={\"eo:cloud_cover\": {\"lt\": 80}},\n",
    ")\n",
    "\n",
    "all_items = search.get_all_items()\n",
    "\n",
    "# Reduce to one per date (there might be some duplicates\n",
    "# based on the location)\n",
    "items = []\n",
    "dates = []\n",
    "for item in all_items:\n",
    "    if item.datetime.date() not in dates:\n",
    "        items.append(item)\n",
    "        dates.append(item.datetime.date())\n",
    "\n",
    "print(f\"Found {len(items)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "items[0].properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coordinate system from first item\n",
    "epsg_str = items[0].properties[\"proj:code\"]\n",
    "epsg = int(epsg_str.split(\":\")[-1])  # Convert 'EPSG:32629' to 32629\n",
    "\n",
    "# Convert point of interest into the image projection\n",
    "# (assumes all images are in the same projection)\n",
    "poidf = gpd.GeoDataFrame(\n",
    "    pd.DataFrame(),\n",
    "    crs=\"EPSG:4326\",\n",
    "    geometry=[Point(lon, lat)],\n",
    ").to_crs(epsg_str)\n",
    "\n",
    "coords = poidf.iloc[0].geometry.coords[0]\n",
    "\n",
    "# Create bounds in projection\n",
    "size = 256\n",
    "gsd = 10\n",
    "bounds = (\n",
    "    coords[0] - (size * gsd) // 2,\n",
    "    coords[1] - (size * gsd) // 2,\n",
    "    coords[0] + (size * gsd) // 2,\n",
    "    coords[1] + (size * gsd) // 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the pixel values, for the bounding box in\n",
    "# the target projection. In this example we use only\n",
    "# the RGB and NIR bands.\n",
    "stack = stackstac.stack(\n",
    "    items,\n",
    "    bounds=bounds,\n",
    "    snap_bounds=False,\n",
    "    epsg=epsg,\n",
    "    resolution=gsd,\n",
    "    dtype=\"float64\",\n",
    "    rescale=False,\n",
    "    fill_value=np.nan,\n",
    "    assets=[\"blue\", \"green\", \"red\", \"nir\"],\n",
    "    resampling=Resampling.nearest,\n",
    ")\n",
    "\n",
    "print(stack)\n",
    "\n",
    "stack = stack.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack.sel(band=[\"red\", \"green\", \"blue\"]).plot.imshow(\n",
    "    row=\"time\", rgb=\"band\", vmin=0, vmax=2000, col_wrap=6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Clay Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "ckpt = \"~/.cache/clay/clay-v1.5.ckpt\"\n",
    "torch.set_default_device(device)\n",
    "\n",
    "model = ClayMAEModule.load_from_checkpoint(\n",
    "    ckpt,\n",
    "    model_size=\"large\",\n",
    "    metadata_path=\"geoai/config/clay_metadata.yaml\",\n",
    "    dolls=[16, 32, 64, 128, 256, 768, 1024],\n",
    "    doll_weights=[1, 1, 1, 1, 1, 1, 1],\n",
    "    mask_ratio=0.0,\n",
    "    shuffle=False,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mean, std, and wavelengths from metadata\n",
    "platform = \"sentinel-2-l2a\"\n",
    "metadata = Box(yaml.safe_load(open(\"geoai/config/clay_metadata.yaml\")))\n",
    "mean = []\n",
    "std = []\n",
    "waves = []\n",
    "# Use the band names to get the correct values in the correct order.\n",
    "for band in stack.band:\n",
    "    mean.append(metadata[platform].bands.mean[str(band.values)])\n",
    "    std.append(metadata[platform].bands.std[str(band.values)])\n",
    "    waves.append(metadata[platform].bands.wavelength[str(band.values)])\n",
    "\n",
    "# Prepare the normalization transform function using the mean and std values.\n",
    "transform = v2.Compose(\n",
    "    [\n",
    "        v2.Normalize(mean=mean, std=std),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep datetimes embedding using a normalization function from the model code.\n",
    "def normalize_timestamp(date):\n",
    "    week = date.isocalendar().week * 2 * np.pi / 52\n",
    "    hour = date.hour * 2 * np.pi / 24\n",
    "\n",
    "    return (math.sin(week), math.cos(week)), (math.sin(hour), math.cos(hour))\n",
    "\n",
    "\n",
    "datetimes = stack.time.values.astype(\"datetime64[s]\").tolist()\n",
    "times = [normalize_timestamp(dat) for dat in datetimes]\n",
    "week_norm = [dat[0] for dat in times]\n",
    "hour_norm = [dat[1] for dat in times]\n",
    "\n",
    "\n",
    "# Prep lat/lon embedding using the\n",
    "def normalize_latlon(lat, lon):\n",
    "    lat = lat * np.pi / 180\n",
    "    lon = lon * np.pi / 180\n",
    "\n",
    "    return (math.sin(lat), math.cos(lat)), (math.sin(lon), math.cos(lon))\n",
    "\n",
    "\n",
    "latlons = [normalize_latlon(lat, lon)] * len(times)\n",
    "lat_norm = [dat[0] for dat in latlons]\n",
    "lon_norm = [dat[1] for dat in latlons]\n",
    "\n",
    "# Normalize pixels\n",
    "pixels = torch.from_numpy(stack.data.astype(np.float32))\n",
    "pixels = transform(pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare additional information\n",
    "datacube = {\n",
    "    \"platform\": platform,\n",
    "    \"time\": torch.tensor(\n",
    "        np.hstack((week_norm, hour_norm)),\n",
    "        dtype=torch.float32,\n",
    "        device=device,\n",
    "    ),\n",
    "    \"latlon\": torch.tensor(\n",
    "        np.hstack((lat_norm, lon_norm)), dtype=torch.float32, device=device\n",
    "    ),\n",
    "    \"pixels\": pixels.to(device),\n",
    "    \"gsd\": torch.tensor(stack.gsd.values, device=device),\n",
    "    \"waves\": torch.tensor(waves, device=device),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    unmsk_patch, unmsk_idx, msk_idx, msk_matrix = model.model.encoder(datacube)\n",
    "\n",
    "# The first embedding is the class token, which is the\n",
    "# overall single embedding. We extract that for PCA below.\n",
    "embeddings_clay = unmsk_patch[:, 0, :].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PCA\n",
    "pca = decomposition.PCA(n_components=1)\n",
    "pca_result = pca.fit_transform(embeddings_clay)\n",
    "\n",
    "plt.xticks(rotation=-45)\n",
    "\n",
    "# Plot all points in blue first\n",
    "plt.scatter(stack.time, pca_result, color=\"blue\")\n",
    "\n",
    "# Re-plot cloudy images in green\n",
    "plt.scatter(stack.time[0], pca_result[0], color=\"green\")\n",
    "plt.scatter(stack.time[2], pca_result[2], color=\"green\")\n",
    "\n",
    "# Color all images after fire in red\n",
    "plt.scatter(stack.time[-5:], pca_result[-5:], color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label the images we downloaded\n",
    "# 0 = Cloud\n",
    "# 1 = Forest\n",
    "# 2 = Fire\n",
    "labels = np.array([0, 1, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2])\n",
    "\n",
    "# Split into fit and test manually, ensuring we have all 3 classes in both sets\n",
    "fit = [0, 1, 3, 4, 7, 8, 9]\n",
    "test = [2, 5, 6, 10, 11]\n",
    "\n",
    "# Train a Support Vector Machine model\n",
    "clf = svm.SVC()\n",
    "clf.fit(embeddings_clay[fit] + 100, labels[fit])\n",
    "\n",
    "# Predict classes on test set\n",
    "prediction = clf.predict(embeddings_clay[test] + 100)\n",
    "\n",
    "# Perfect match for SVM\n",
    "match = np.sum(labels[test] == prediction)\n",
    "print(f\"Matched {match} out of {len(test)} correctly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_clay.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## GeoAI Wrapper Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geoai.clay import Clay\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Clay model using geoai wrapper with custom metadata for 4 bands\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Create custom metadata for just the 4 bands we're using\n",
    "custom_metadata = {\n",
    "    \"band_order\": [\"blue\", \"green\", \"red\", \"nir\"],\n",
    "    \"rgb_indices\": [2, 1, 0],\n",
    "    \"gsd\": 10,\n",
    "    \"bands\": {\n",
    "        \"mean\": {\"blue\": 1105.0, \"green\": 1355.0, \"red\": 1552.0, \"nir\": 2743.0},\n",
    "        \"std\": {\"blue\": 1809.0, \"green\": 1757.0, \"red\": 1888.0, \"nir\": 1742.0},\n",
    "        \"wavelength\": {\"blue\": 0.493, \"green\": 0.56, \"red\": 0.665, \"nir\": 0.842},\n",
    "    },\n",
    "}\n",
    "\n",
    "clay_model = Clay(custom_metadata=custom_metadata, device=str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert WGS84 bounds for Clay model\n",
    "# First convert stack bounds back to WGS84\n",
    "proj_bounds = (bounds[0], bounds[1], bounds[2], bounds[3])\n",
    "bounds_gdf = gpd.GeoDataFrame(\n",
    "    geometry=[Point(bounds[0], bounds[1]), Point(bounds[2], bounds[3])], crs=epsg_str\n",
    ").to_crs(\"EPSG:4326\")\n",
    "\n",
    "wgs84_bounds = (\n",
    "    bounds_gdf.iloc[0].geometry.x,  # min_lon\n",
    "    bounds_gdf.iloc[0].geometry.y,  # min_lat\n",
    "    bounds_gdf.iloc[1].geometry.x,  # max_lon\n",
    "    bounds_gdf.iloc[1].geometry.y,  # max_lat\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each image through Clay model\n",
    "embeddings_list = []\n",
    "datetimes = stack.time.values.astype(\"datetime64[s]\").tolist()\n",
    "\n",
    "for i, datetime_obj in enumerate(datetimes):\n",
    "    # Extract image for this time step [H, W, C]\n",
    "    image = stack[i].values.transpose(1, 2, 0)  # Convert from [C, H, W] to [H, W, C]\n",
    "\n",
    "    # Convert numpy datetime64 to Python datetime\n",
    "    if hasattr(datetime_obj, \"astype\"):\n",
    "        timestamp = datetime_obj.astype(\"datetime64[s]\").astype(\"int\")\n",
    "        date = datetime.datetime.fromtimestamp(timestamp)\n",
    "    else:\n",
    "        date = datetime_obj\n",
    "\n",
    "    # Generate embedding using geoai wrapper\n",
    "    embed = clay_model.generate(\n",
    "        image=image,\n",
    "        bounds=wgs84_bounds,\n",
    "        date=date,\n",
    "        gsd=gsd,\n",
    "        only_cls_token=True,  # Get only the class token (global embedding)\n",
    "    )\n",
    "\n",
    "    embeddings_list.append(embed.squeeze(0))\n",
    "# Stack all embeddingsnp\n",
    "embeddings_geoai = torch.stack(embeddings_list).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_geoai.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PCA\n",
    "pca = decomposition.PCA(n_components=1)\n",
    "pca_result = pca.fit_transform(embeddings_geoai)\n",
    "\n",
    "plt.xticks(rotation=-45)\n",
    "\n",
    "# Plot all points in blue first\n",
    "plt.scatter(stack.time, pca_result, color=\"blue\")\n",
    "\n",
    "# Re-plot cloudy images in green\n",
    "plt.scatter(stack.time[0], pca_result[0], color=\"green\")\n",
    "plt.scatter(stack.time[2], pca_result[2], color=\"green\")\n",
    "\n",
    "# Color all images after fire in red\n",
    "plt.scatter(stack.time[-5:], pca_result[-5:], color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Generated embeddings shape: {embeddings_geoai.shape}\")\n",
    "\n",
    "# Label the images we downloaded\n",
    "# 0 = Cloud\n",
    "# 1 = Forest\n",
    "# 2 = Fire\n",
    "labels = np.array([0, 1, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2])\n",
    "\n",
    "# Split into fit and test manually, ensuring we have all 3 classes in both sets\n",
    "fit = [0, 1, 3, 4, 7, 8, 9]\n",
    "test = [2, 5, 6, 10, 11]\n",
    "\n",
    "# Train a Support Vector Machine model\n",
    "clf = svm.SVC()\n",
    "clf.fit(embeddings_geoai[fit] + 100, labels[fit])\n",
    "\n",
    "# Predict classes on test set\n",
    "prediction = clf.predict(embeddings_geoai[test] + 100)\n",
    "\n",
    "# Perfect match for SVM\n",
    "match = np.sum(labels[test] == prediction)\n",
    "print(f\"Matched {match} out of {len(test)} correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Comparing GeoAI and Clay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(embeddings_geoai, embeddings_clay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "((embeddings_geoai - embeddings_clay) / embeddings_clay).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
