{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wetland Mapping with Foundation Models\n",
    "\n",
    "[![image](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/opengeos/geoai/blob/main/docs/examples/wetland_foundation_model.ipynb)\n",
    "\n",
    "This notebook demonstrates how to train and deploy wetland mapping models using Satlas Aerial foundation models, NAIP imagery, and National Wetlands Inventory (NWI) data.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Foundation Model Backbone**: Uses Allen AI's Satlas Aerial (Swin-v2-Base pre-trained on NAIP aerial imagery)\n",
    "- **Automated Data Pipeline**: Downloads NAIP imagery and NWI data via existing GeoAI infrastructure\n",
    "- **Multi-Class Wetland Detection**: Classifies wetlands into 6 categories\n",
    "- **Scalable Training**: PyTorch Lightning with progressive unfreezing\n",
    "- **Large Image Inference**: Continental-scale mapping capability\n",
    "\n",
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install required packages\n",
    "# %pip install geoai-py lightning leafmap satlaspretrain-models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geoai\n",
    "import leafmap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"GeoAI version: {geoai.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Explore Available Foundation Models\n",
    "\n",
    "First, let's explore the Satlas Aerial foundation model used as the default backbone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Satlas Aerial backbone availability\n",
    "import satlaspretrain_models\n",
    "\n",
    "print(\"Satlas Aerial backbone: Swin-v2-Base pre-trained on NAIP imagery\")\n",
    "print(\"Source: https://huggingface.co/allenai/satlas-pretrain\")\n",
    "print()\n",
    "print(\"Model Details:\")\n",
    "print(\"  - Architecture: Swin-v2-Base transformer\")\n",
    "print(\"  - Pre-training: 26.5 million NAIP aerial images\")\n",
    "print(\"  - Developed by: Allen AI Institute\")\n",
    "print(\"  - Input channels: RGB (3 channels)\")\n",
    "print(\"  - Spatial resolution: 0.6m per pixel\")\n",
    "print(\n",
    "    \"\\nNote: Prithvi is still available as an alternative backbone with backbone='prithvi'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Study Region\n",
    "\n",
    "Let's select a region with diverse wetland types. We'll use North Dakota's prairie pothole region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define study region - North Dakota prairie pothole area\n",
    "study_bbox = (-99.3, 46.8, -99.0, 47.1)  # (min_lon, min_lat, max_lon, max_lat)\n",
    "year = 2020\n",
    "\n",
    "print(f\"Study region: {study_bbox}\")\n",
    "print(f\"NAIP year: {year}\")\n",
    "\n",
    "# Create interactive map to visualize the region\n",
    "m = leafmap.Map(center=[46.95, -99.15], zoom=10)\n",
    "m.add_basemap(\"Esri.WorldImagery\")\n",
    "\n",
    "# Add study area boundary\n",
    "bbox_gdf = leafmap.bbox_to_gdf(study_bbox)\n",
    "m.add_gdf(\n",
    "    bbox_gdf,\n",
    "    layer_name=\"Study Area\",\n",
    "    style={\"color\": \"red\", \"weight\": 3, \"fillOpacity\": 0},\n",
    ")\n",
    "\n",
    "# Add NWI layer for context\n",
    "m.add_basemap(\"FWS NWI Wetlands\", opacity=0.6)\n",
    "\n",
    "print(\"\\nInteractive map showing study region:\")\n",
    "print(\"- Red outline: Study area boundary\")\n",
    "print(\"- Blue areas: Existing NWI wetland data\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore Wetland Classes\n",
    "\n",
    "Our foundation model will classify wetlands into 6 main categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get wetland class definitions\n",
    "wetland_classes = geoai.get_wetland_classes()\n",
    "\n",
    "print(\"Wetland Classification System:\")\n",
    "print(\"=============================\")\n",
    "for class_name, class_id in wetland_classes.items():\n",
    "    descriptions = {\n",
    "        \"background\": \"Non-wetland areas (uplands, agriculture, urban)\",\n",
    "        \"freshwater_emergent\": \"Palustrine emergent wetlands (cattails, sedges)\",\n",
    "        \"freshwater_forested\": \"Palustrine forested wetlands (swamps, wet forests)\",\n",
    "        \"freshwater_pond\": \"Open water and pond habitats\",\n",
    "        \"estuarine\": \"Estuarine and marine wetlands (salt marshes)\",\n",
    "        \"other_wetland\": \"Other wetland types (scrub-shrub, etc.)\",\n",
    "    }\n",
    "\n",
    "    desc = descriptions.get(class_name, \"Other wetland type\")\n",
    "    print(f\"  {class_id}: {class_name.replace('_', ' ').title()}\")\n",
    "    print(f\"     {desc}\")\n",
    "    print()\n",
    "\n",
    "print(f\"Total classes: {len(wetland_classes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Training Dataset\n",
    "\n",
    "Now let's create a complete wetland training dataset by downloading NAIP imagery and NWI data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset using the convenience function\n",
    "print(\"Creating wetland training dataset...\")\n",
    "print(\"This will:\")\n",
    "print(\"1. Download NAIP imagery from Planetary Computer\")\n",
    "print(\"2. Fetch NWI wetland data\")\n",
    "print(\"3. Create training tiles with wetland masks\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    dataset_stats = geoai.create_wetland_dataset(\n",
    "        bbox=study_bbox,\n",
    "        output_dir=\"wetland_training_data\",\n",
    "        year=year,\n",
    "        max_naip_items=5,  # Download up to 15 NAIP tiles\n",
    "        tile_size=512,  # 512x512 pixel training tiles\n",
    "        min_wetland_pixels=50,  # Minimum wetland pixels to include tile\n",
    "    )\n",
    "\n",
    "    print(\"\\nDataset Creation Results:\")\n",
    "    print(\"========================\")\n",
    "    print(f\"NAIP files downloaded: {dataset_stats['naip_files_downloaded']}\")\n",
    "    print(f\"Wetland features found: {dataset_stats['wetland_features_found']}\")\n",
    "    print(f\"Total training tiles: {dataset_stats['total_tiles']}\")\n",
    "    print(f\"Wetland tiles: {dataset_stats['wetland_tiles']}\")\n",
    "    print(f\"Files processed: {dataset_stats['files_processed']}\")\n",
    "    print(f\"Dataset directory: {dataset_stats['dataset_dir']}\")\n",
    "\n",
    "    dataset_created = dataset_stats[\"wetland_tiles\"] > 0\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error creating dataset: {e}\")\n",
    "    dataset_created = False\n",
    "    dataset_stats = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Visualize Training Data\n",
    "\n",
    "Let's examine some of the training tiles we created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_created:\n",
    "    # List some training files\n",
    "    images_dir = Path(\"wetland_training_data/images\")\n",
    "    masks_dir = Path(\"wetland_training_data/masks\")\n",
    "\n",
    "    image_files = list(images_dir.glob(\"*.tif\"))[:5]  # First 5 files\n",
    "\n",
    "    if image_files:\n",
    "        print(\n",
    "            f\"Sample training files (showing first 5 of {len(list(images_dir.glob('*.tif')))}):\"\n",
    "        )\n",
    "        for img_file in image_files:\n",
    "            mask_file = masks_dir / img_file.name\n",
    "            print(f\"  Image: {img_file.name}\")\n",
    "            print(f\"  Mask:  {mask_file.name}\")\n",
    "            print()\n",
    "\n",
    "        # Show file sizes\n",
    "        total_size_mb = sum(f.stat().st_size for f in images_dir.glob(\"*.tif\")) / (\n",
    "            1024**2\n",
    "        )\n",
    "        print(f\"Total dataset size: {total_size_mb:.1f} MB\")\n",
    "    else:\n",
    "        print(\"No training files found.\")\n",
    "else:\n",
    "    print(\"Skipping visualization - no training data was created.\")\n",
    "    print(\"Try a different region with more wetland coverage.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Examine Foundation Model Architecture\n",
    "\n",
    "Let's understand the wetland foundation model using Satlas Aerial backbone that we're about to train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample model to examine architecture\n",
    "print(\"=== Wetland Foundation Model Architecture ===\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    sample_model = geoai.WetlandSatlasModel(\n",
    "        num_wetland_classes=6, freeze_backbone_epochs=2\n",
    "    )\n",
    "\n",
    "    # Show model info\n",
    "    print(f\"Foundation Backbone: Satlas Aerial (Swin-v2-Base)\")\n",
    "    print(f\"  - Pre-trained on 26.5M NAIP aerial images\")\n",
    "    print(f\"  - Architecture: Hierarchical Vision Transformer\")\n",
    "    print(f\"  - Input: RGB imagery (3 channels)\")\n",
    "    print(f\"  - Spatial understanding of aerial imagery patterns\")\n",
    "\n",
    "    print(f\"\\nTask-Specific Components:\")\n",
    "    print(f\"  - Feature Pyramid Network (FPN): Multi-scale feature fusion\")\n",
    "    print(f\"  - Segmentation head: Convolutional layers for pixel-wise classification\")\n",
    "    print(f\"  - Output classes: {sample_model.num_classes}\")\n",
    "    print(f\"  - Freeze backbone: First {sample_model.freeze_backbone_epochs} epochs\")\n",
    "\n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in sample_model.parameters())\n",
    "    trainable_params = sum(\n",
    "        p.numel() for p in sample_model.parameters() if p.requires_grad\n",
    "    )\n",
    "\n",
    "    print(f\"\\nModel Parameters:\")\n",
    "    print(f\"  Total: {total_params:,}\")\n",
    "    print(f\"  Initially trainable: {trainable_params:,}\")\n",
    "    print(f\"  Initially frozen: {total_params - trainable_params:,}\")\n",
    "\n",
    "    print(f\"\\nTraining Strategy:\")\n",
    "    print(f\"  1. Freeze Satlas backbone (preserve foundation knowledge)\")\n",
    "    print(f\"  2. Train only FPN and segmentation head\")\n",
    "    print(f\"  3. Progressively unfreeze backbone for fine-tuning\")\n",
    "\n",
    "    model_architecture_ready = True\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error examining model: {e}\")\n",
    "    print(\"This may be due to missing dependencies or model files.\")\n",
    "    model_architecture_ready = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Train the Wetland Foundation Model\n",
    "\n",
    "Now let's train our model (if we have sufficient training data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model if we have sufficient data\n",
    "min_required_tiles = 20  # Minimum for demo\n",
    "\n",
    "if dataset_created and dataset_stats.get(\"wetland_tiles\", 0) >= min_required_tiles:\n",
    "    print(\"=== Training Wetland Foundation Model ===\")\n",
    "    print(f\"Training with {dataset_stats['wetland_tiles']} wetland tiles\")\n",
    "    print()\n",
    "\n",
    "    try:\n",
    "        training_results = geoai.train_wetland_model(\n",
    "            dataset_dir=\"wetland_training_data\",\n",
    "            output_dir=\"wetland_model_output\",\n",
    "            backbone=\"satlas\",\n",
    "            batch_size=4,\n",
    "            max_epochs=30,\n",
    "            learning_rate=1e-4,\n",
    "            val_split=0.2,\n",
    "            freeze_backbone_epochs=2,\n",
    "        )\n",
    "\n",
    "        print(\"\\nüéâ Training Completed Successfully!\")\n",
    "        print(f\"Best model: {training_results['best_model_path']}\")\n",
    "        print(f\"Checkpoint: {training_results['checkpoint_path']}\")\n",
    "        print(f\"Output directory: {training_results['output_dir']}\")\n",
    "\n",
    "        model_trained = True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Training failed: {e}\")\n",
    "        print(\n",
    "            \"This may be due to insufficient GPU memory, missing dependencies, or data issues.\"\n",
    "        )\n",
    "        model_trained = False\n",
    "        training_results = {}\n",
    "\n",
    "else:\n",
    "    print(f\"Insufficient training data for model training.\")\n",
    "    print(f\"Found: {dataset_stats.get('wetland_tiles', 0)} tiles\")\n",
    "    print(f\"Required: {min_required_tiles} tiles\")\n",
    "    print()\n",
    "    print(\"For production training, you would:\")\n",
    "    print(\"1. Use a larger study region or multiple regions\")\n",
    "    print(\"2. Download 50+ NAIP tiles\")\n",
    "    print(\"3. Train for 50-100 epochs\")\n",
    "    print(\"4. Use larger batch sizes on GPU\")\n",
    "\n",
    "    model_trained = False\n",
    "    training_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Resume Training (Optional)\n",
    "\n",
    "If training was interrupted or you want to continue for more epochs, you can resume from the last checkpoint without starting over:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume training from last checkpoint (increase max_epochs to train longer)\n",
    "# Uncomment below to resume:\n",
    "\n",
    "training_results = geoai.train_wetland_model(\n",
    "    dataset_dir=\"wetland_training_data\",\n",
    "    output_dir=\"wetland_model_output\",\n",
    "    backbone=\"satlas\",\n",
    "    batch_size=4,\n",
    "    max_epochs=30,  # Increase to train further\n",
    "    learning_rate=1e-4,\n",
    "    val_split=0.2,\n",
    "    freeze_backbone_epochs=2,\n",
    "    resume_from=\"last\",  # Auto-detect last checkpoint\n",
    ")\n",
    "\n",
    "model_trained = True\n",
    "# You can also resume from a specific checkpoint:\n",
    "# training_results = geoai.train_wetland_model(\n",
    "#     ...,\n",
    "#     resume_from=\"wetland_model_output/checkpoints/wetland-satlas-epoch=03-val_loss=0.373.ckpt\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Model Inference Demo\n",
    "\n",
    "If training was successful, let's run inference on a new image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_trained and dataset_stats.get(\"naip_files_downloaded\", 0) > 0:\n",
    "    print(\"=== Running Wetland Prediction ===\")\n",
    "\n",
    "    # Get list of downloaded NAIP files for testing\n",
    "    naip_cache_dir = Path(\"wetland_data_cache/naip\")\n",
    "    naip_files = list(naip_cache_dir.glob(\"*.tif\"))\n",
    "\n",
    "    if naip_files:\n",
    "        # Use first NAIP file as test case\n",
    "        test_raster = str(naip_files[0])\n",
    "        output_prediction = \"wetland_prediction_demo.tif\"\n",
    "\n",
    "        print(f\"Test raster: {test_raster}\")\n",
    "        print(f\"Output: {output_prediction}\")\n",
    "\n",
    "        try:\n",
    "            # Run inference\n",
    "            prediction_result = geoai.predict_wetlands_large_image(\n",
    "                model_path=training_results[\"best_model_path\"],\n",
    "                input_raster=test_raster,\n",
    "                output_path=output_prediction,\n",
    "                tile_size=512,\n",
    "                overlap=64,\n",
    "            )\n",
    "\n",
    "            print(f\"\\n‚úÖ Prediction completed: {prediction_result}\")\n",
    "            inference_successful = True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Inference failed: {e}\")\n",
    "            inference_successful = False\n",
    "    else:\n",
    "        print(\"No NAIP files found for testing\")\n",
    "        inference_successful = False\n",
    "\n",
    "else:\n",
    "    print(\"Skipping inference - model not trained or no test data available\")\n",
    "    inference_successful = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Visualize Results\n",
    "\n",
    "Let's create an interactive map showing the wetland predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if inference_successful and Path(\"wetland_prediction_demo.tif\").exists():\n",
    "    print(\"=== Visualizing Wetland Predictions ===\")\n",
    "\n",
    "    try:\n",
    "        # Create visualization map\n",
    "        naip_file = str(list(Path(\"wetland_data_cache/naip\").glob(\"*.tif\"))[0])\n",
    "\n",
    "        viz_map = geoai.visualize_wetland_predictions(\n",
    "            prediction_path=\"wetland_prediction_demo.tif\",\n",
    "            naip_path=naip_file,\n",
    "            center=[46.95, -99.15],\n",
    "        )\n",
    "\n",
    "        print(\"Interactive map with wetland predictions:\")\n",
    "        print(\"- Background: NAIP imagery (NIR-Red-Green false color)\")\n",
    "        print(\"- Overlay: Wetland classification predictions\")\n",
    "        print(\"- Legend: Color-coded wetland classes\")\n",
    "\n",
    "        viz_map\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Visualization failed: {e}\")\n",
    "        print(\"This may be due to missing leafmap or file access issues.\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping visualization - no prediction results available\")\n",
    "    print()\n",
    "    print(\"In a complete workflow, you would see:\")\n",
    "    print(\"üó∫Ô∏è  Interactive map with NAIP imagery background\")\n",
    "    print(\"üé®  Color-coded wetland classifications overlay\")\n",
    "    print(\"üìä  Legend showing the 6 wetland classes\")\n",
    "    print(\"üîç  Ability to zoom and explore predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Production Scaling Tips\n",
    "\n",
    "For deploying this as a production wetland mapping system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Production Deployment Guide ===\")\n",
    "print()\n",
    "\n",
    "print(\"üî¨ **Research & Development:**\")\n",
    "print(\"  ‚Ä¢ Multi-region training: 5,000-10,000+ tiles across diverse ecoregions\")\n",
    "print(\"  ‚Ä¢ Temporal analysis: Include multiple seasons/years of NAIP imagery\")\n",
    "print(\"  ‚Ä¢ Cross-validation: Geographic holdout regions for robust evaluation\")\n",
    "print(\"  ‚Ä¢ Field validation: GPS ground truth data for accuracy assessment\")\n",
    "print()\n",
    "\n",
    "print(\"‚ö° **Model Optimization:**\")\n",
    "print(\"  ‚Ä¢ Backbone options: Satlas Aerial (default) or Prithvi for comparison\")\n",
    "print(\"  ‚Ä¢ Architecture improvements: Multi-scale fusion, attention mechanisms\")\n",
    "print(\"  ‚Ä¢ Training optimization: Mixed precision, gradient accumulation, DDP\")\n",
    "print(\"  ‚Ä¢ Ensemble methods: Combine multiple models for robustness\")\n",
    "print()\n",
    "\n",
    "print(\"üåç **Scale & Deployment:**\")\n",
    "print(\"  ‚Ä¢ Cloud infrastructure: AWS/GCP with GPU clusters\")\n",
    "print(\"  ‚Ä¢ Model serving: TensorRT optimization, ONNX conversion\")\n",
    "print(\"  ‚Ä¢ API deployment: FastAPI + Docker for scalable inference\")\n",
    "print(\"  ‚Ä¢ Integration: Google Earth Engine for global monitoring\")\n",
    "print()\n",
    "\n",
    "print(\"üìä **Monitoring & Validation:**\")\n",
    "print(\"  ‚Ä¢ Continuous validation: Compare with new field surveys\")\n",
    "print(\"  ‚Ä¢ Change detection: Monitor wetland loss/gain over time\")\n",
    "print(\"  ‚Ä¢ Model drift: Retrain periodically with new data\")\n",
    "print(\"  ‚Ä¢ Uncertainty quantification: Provide confidence scores\")\n",
    "print()\n",
    "\n",
    "print(\"üîó **Ecosystem Integration:**\")\n",
    "print(\"  ‚Ä¢ GeoAI ecosystem: Seamless integration with geemap, leafmap\")\n",
    "print(\"  ‚Ä¢ Open science: Model sharing via HuggingFace Hub\")\n",
    "print(\"  ‚Ä¢ Standards: STAC-compliant metadata and outputs\")\n",
    "print(\"  ‚Ä¢ Community: Collaborate with wetland scientists and managers\")\n",
    "\n",
    "# Show example production code\n",
    "print(\"\\nüìù **Example Production Code:**\")\n",
    "print(\"```python\")\n",
    "print(\"# Continental-scale wetland mapping\")\n",
    "print(\"import geoai\")\n",
    "print(\"\")\n",
    "print(\"# Train on multiple regions\")\n",
    "print(\"regions = [\")\n",
    "print(\"    (-99, 46, -97, 48),  # North Dakota\")\n",
    "print(\"    (-84, 25, -80, 27),  # Florida Everglades\")\n",
    "print(\"    (-73, 40, -70, 42),  # Northeast coast\")\n",
    "print(\"]\")\n",
    "print(\"\")\n",
    "print(\"for region in regions:\")\n",
    "print(\"    geoai.create_wetland_dataset(region, f'training_{i}')\")\n",
    "print(\"\")\n",
    "print(\"# Train production model\")\n",
    "print(\"geoai.train_wetland_model(\")\n",
    "print(\"    'combined_training_data',\")\n",
    "print(\"    backbone='satlas',\")\n",
    "print(\"    max_epochs=100,\")\n",
    "print(\"    batch_size=16\")\n",
    "print(\")\")\n",
    "print(\"```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "üéâ **What we've demonstrated:**\n",
    "\n",
    "1. **Foundation Model Pipeline**: Complete wetland mapping system using Satlas Aerial\n",
    "2. **Automated Data Access**: NAIP imagery + NWI data via existing GeoAI infrastructure\n",
    "3. **Multi-Class Classification**: 6 wetland categories with class-aware training\n",
    "4. **Transfer Learning**: Leverage 26.5M NAIP aerial imagery pre-training\n",
    "5. **Scalable Architecture**: PyTorch Lightning with progressive unfreezing\n",
    "6. **Production Ready**: Large-scale inference and visualization capabilities\n",
    "\n",
    "üöÄ **Key advantages over traditional approaches:**\n",
    "\n",
    "- **Rich Representation**: Foundation models understand complex Earth patterns\n",
    "- **Data Efficiency**: Less training data needed due to pre-training\n",
    "- **Generalization**: Better performance across different regions/seasons\n",
    "- **Scalability**: Cloud-native architecture for continental mapping\n",
    "- **Integration**: Seamless with existing GeoAI ecosystem\n",
    "\n",
    "This represents the **future of environmental monitoring** - combining the power of foundation models with domain expertise for accurate, scalable wetland mapping.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Expand training data**: Collect samples from multiple ecoregions\n",
    "2. **Optimize model**: Try different backbone options and architectures\n",
    "3. **Field validation**: Compare predictions with ground truth surveys\n",
    "4. **Scale deployment**: Set up cloud infrastructure for production use\n",
    "5. **Contribute**: Share trained models and improvements with the community\n",
    "\n",
    "## Learn More\n",
    "\n",
    "- **GeoAI Documentation**: [https://opengeoai.org](https://opengeos.org)\n",
    "- **Satlas Aerial Foundation Model**: [https://huggingface.co/allenai/satlas-pretrain](https://huggingface.co/allenai/satlas-pretrain)\n",
    "- **Prithvi Foundation Model** (alternative): [https://huggingface.co/ibm-nasa-geospatial](https://huggingface.co/ibm-nasa-geospatial)\n",
    "- **NAIP Imagery**: [https://planetarycomputer.microsoft.com/dataset/naip](https://planetarycomputer.microsoft.com/dataset/naip)\n",
    "- **National Wetlands Inventory**: [https://www.fws.gov/program/national-wetlands-inventory](https://www.fws.gov/program/national-wetlands-inventory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
