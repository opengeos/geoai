{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX Model Support for Geospatial Inference\n",
    "\n",
    "[![image](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/opengeos/geoai/blob/main/docs/examples/onnx.ipynb)\n",
    "\n",
    "This notebook demonstrates how to use ONNX Runtime with GeoAI for efficient geospatial model inference. The ONNX module mirrors the `AutoGeoModel` API, allowing you to export Hugging Face models to ONNX format and run inference on GeoTIFF data using ONNX Runtime.\n",
    "\n",
    "## Why ONNX?\n",
    "\n",
    "- **Faster inference**: ONNX Runtime provides optimized execution across different hardware\n",
    "- **Edge deployment**: Run models without PyTorch or GPU drivers\n",
    "- **Cross-platform**: Deploy on Windows, Linux, macOS, and mobile devices\n",
    "- **Smaller footprint**: No need for full PyTorch installation at inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U geoai-py[onnx] transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geoai import download_file\n",
    "from geoai.onnx import (\n",
    "    export_to_onnx,\n",
    "    ONNXGeoModel,\n",
    "    onnx_semantic_segmentation,\n",
    "    onnx_image_classification,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Sample Data\n",
    "\n",
    "Download sample aerial imagery for the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://huggingface.co/datasets/giswqs/geospatial/resolve/main/aerial.tif\"\n",
    "image_path = download_file(image_url, \"aerial.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Export a Hugging Face Model to ONNX\n",
    "\n",
    "The `export_to_onnx()` function converts a pretrained Hugging Face model to ONNX format. It automatically handles model loading, tracing, and saving metadata (label mappings, input sizes, task type) to a sidecar JSON file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export a Semantic Segmentation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_onnx_path = export_to_onnx(\n",
    "    \"nvidia/segformer-b0-finetuned-ade-512-512\",\n",
    "    \"segformer.onnx\",\n",
    "    task=\"semantic-segmentation\",\n",
    ")\n",
    "print(f\"Model exported to: {seg_onnx_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export an Image Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_onnx_path = export_to_onnx(\n",
    "    \"google/vit-base-patch16-224\",\n",
    "    \"vit_classifier.onnx\",\n",
    "    task=\"image-classification\",\n",
    "    input_height=224,\n",
    "    input_width=224,\n",
    ")\n",
    "print(f\"Model exported to: {cls_onnx_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Semantic Segmentation with ONNX\n",
    "\n",
    "### Using ONNXGeoModel Directly\n",
    "\n",
    "The `ONNXGeoModel` class provides full control over inference. It supports tiled processing for large GeoTIFF files and preserves georeferencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ONNXGeoModel(\"segformer.onnx\", task=\"semantic-segmentation\")\n",
    "\n",
    "result = model.predict(\n",
    "    image_path,\n",
    "    output_path=\"segmentation_onnx.tif\",\n",
    ")\n",
    "\n",
    "mask = result.get(\"mask\", result.get(\"output\"))\n",
    "print(f\"Segmentation mask shape: {mask.shape}\")\n",
    "print(f\"Unique classes: {len(set(mask.flatten()))}\")\n",
    "print(f\"Output saved to: segmentation_onnx.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize Segmentation Results\n",
    "\n",
    "Save segmentation results as both raster (GeoTIFF) and vector (GeoJSON) outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(\n",
    "    image_path,\n",
    "    output_path=\"segmentation_onnx.tif\",\n",
    "    output_vector_path=\"segmentation_onnx.geojson\",\n",
    "    min_object_area=50,\n",
    "    simplify_tolerance=1.0,\n",
    ")\n",
    "\n",
    "if \"geodataframe\" in result:\n",
    "    print(\"Vectorized segmentation saved to segmentation_onnx.geojson\")\n",
    "    print(f\"Number of polygons: {len(result['geodataframe'])}\")\n",
    "    print(result[\"geodataframe\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Convenience Function\n",
    "\n",
    "The `onnx_semantic_segmentation()` function provides a simpler interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = onnx_semantic_segmentation(\n",
    "    image_path,\n",
    "    output_path=\"segmentation_onnx2.tif\",\n",
    "    model_path=\"segformer.onnx\",\n",
    "    output_vector_path=\"segmentation_onnx2.geojson\",\n",
    "    min_object_area=50,\n",
    ")\n",
    "\n",
    "print(f\"Segmentation complete\")\n",
    "if \"geodataframe\" in result:\n",
    "    print(f\"Number of polygons: {len(result['geodataframe'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image Classification with ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cls_result = onnx_image_classification(\n",
    "    image_path,\n",
    "    model_path=\"vit_classifier.onnx\",\n",
    ")\n",
    "\n",
    "print(f\"Predicted class index: {cls_result.get('class')}\")\n",
    "if cls_result.get(\"label\"):\n",
    "    print(f\"Predicted label: {cls_result['label']}\")\n",
    "\n",
    "if \"probabilities\" in cls_result and cls_result[\"probabilities\"] is not None:\n",
    "    probs = cls_result[\"probabilities\"]\n",
    "    top_indices = np.argsort(probs)[-5:][::-1]\n",
    "    print(\"\\nTop 5 predictions:\")\n",
    "    for idx in top_indices:\n",
    "        label = cls_result.get(\"label\", f\"Class {idx}\") if idx == cls_result.get(\"class\") else f\"Class {idx}\"\n",
    "        print(f\"  {label}: {probs[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ONNXGeoModel for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_model = ONNXGeoModel(\"vit_classifier.onnx\", task=\"image-classification\")\n",
    "\n",
    "cls_result = cls_model.predict(image_path)\n",
    "\n",
    "print(f\"Predicted class: {cls_result.get('class')}\")\n",
    "print(f\"Label: {cls_result.get('label', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performance Notes\n",
    "\n",
    "ONNX Runtime provides several advantages over PyTorch for inference:\n",
    "\n",
    "| Feature | PyTorch | ONNX Runtime |\n",
    "|---|---|---|\n",
    "| Installation size | Large (~2 GB+) | Small (~50 MB) |\n",
    "| GPU requirement | Often needed | CPU-optimized |\n",
    "| Edge deployment | Difficult | Straightforward |\n",
    "| Cross-platform | Python-centric | C++, C#, Java, JS, etc. |\n",
    "| Inference speed | Baseline | Often 1.5-3x faster |\n",
    "\n",
    "ONNX models are ideal for:\n",
    "- **Production deployment**: Smaller, faster, no training framework needed\n",
    "- **Edge devices**: Run on IoT devices, drones, and embedded systems\n",
    "- **Web applications**: Use ONNX.js or ONNX Runtime Web\n",
    "- **Batch processing**: Faster throughput for large-scale geospatial workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "files_to_remove = [\n",
    "    \"aerial.tif\",\n",
    "    \"segformer.onnx\",\n",
    "    \"segformer.onnx.json\",\n",
    "    \"vit_classifier.onnx\",\n",
    "    \"vit_classifier.onnx.json\",\n",
    "    \"segmentation_onnx.tif\",\n",
    "    \"segmentation_onnx.geojson\",\n",
    "    \"segmentation_onnx2.tif\",\n",
    "    \"segmentation_onnx2.geojson\",\n",
    "]\n",
    "\n",
    "for f in files_to_remove:\n",
    "    if os.path.exists(f):\n",
    "        os.remove(f)\n",
    "        print(f\"Removed {f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 4,
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
