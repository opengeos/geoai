{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Building Detection with WHU Pre-trained Model\n",
    "\n",
    "[![image](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/opengeos/geoai/blob/main/docs/examples/building_detection_whu.ipynb)\n",
    "\n",
    "This notebook demonstrates building detection using a semantic segmentation model trained on the [WHU Building Dataset](https://study.rsgis.whu.edu.cn/pages/download/building_dataset.html). The model uses an **EfficientNet-B4** encoder with a **UNet++** decoder architecture, trained on high-resolution (0.3m) aerial imagery.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Pre-trained model** loaded directly from HuggingFace Hub\n",
    "- **Sliding-window inference** for processing large aerial imagery\n",
    "- **Vectorization** of predicted masks into building footprint polygons\n",
    "- **Geometric analysis** with area, perimeter, and other properties\n",
    "\n",
    "## Install package\n",
    "\n",
    "To use the `geoai-py` package, ensure it is installed in your environment. Uncomment the command below if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install geoai-py timm segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geoai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Download sample data\n",
    "\n",
    "Download sample aerial imagery for building detection. This is a high-resolution (0.3m) aerial image suitable for building extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_url = \"https://huggingface.co/datasets/giswqs/geospatial/resolve/main/whu_building_test.tif\"\n",
    "raster_path = geoai.download_file(raster_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Visualize input data\n",
    "\n",
    "View the aerial imagery to understand the study area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "geoai.view_raster(raster_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Run building detection\n",
    "\n",
    "Use the pre-trained model from HuggingFace Hub to detect buildings. The `timm_segmentation_from_hub` function automatically downloads the model and configuration, then runs sliding-window inference on the input image.\n",
    "\n",
    "**Model details:**\n",
    "- **Architecture**: UNet++ with EfficientNet-B4 encoder\n",
    "- **Training data**: WHU Building Dataset (0.3m aerial imagery)\n",
    "- **Classes**: Background (0) and Building (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"whu_building_prediction.tif\"\n",
    "\n",
    "geoai.timm_segmentation_from_hub(\n",
    "    input_path=raster_path,\n",
    "    output_path=output_path,\n",
    "    repo_id=\"giswqs/whu-building-unetplusplus-efficientnet-b4\",\n",
    "    window_size=512,\n",
    "    overlap=256,\n",
    "    batch_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Visualize raster mask\n",
    "\n",
    "View the predicted building mask overlaid on the input imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "geoai.view_raster(output_path, nodata=0, basemap=raster_path, backend=\"ipyleaflet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Vectorize masks\n",
    "\n",
    "Convert the predicted raster mask to vector building footprint polygons. The `orthogonalize` function extracts polygons and regularizes their shapes to have right angles, which is typical for buildings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_vector_path = \"whu_building_footprints.geojson\"\n",
    "gdf = geoai.orthogonalize(\n",
    "    input_path=output_path,\n",
    "    output_path=output_vector_path,\n",
    "    epsilon=2.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Add geometric properties\n",
    "\n",
    "Calculate geometric properties such as area and perimeter for each detected building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_props = geoai.add_geometric_properties(gdf, area_unit=\"m2\", length_unit=\"m\")\n",
    "gdf_props.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Filter small artifacts\n",
    "\n",
    "Remove small detected regions that are unlikely to be actual buildings. A minimum area threshold helps reduce false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_filtered = gdf_props[gdf_props[\"area_m2\"] > 20]\n",
    "print(f\"Buildings detected: {len(gdf_filtered)}\")\n",
    "print(f\"Removed {len(gdf_props) - len(gdf_filtered)} small artifacts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Visualize building footprints\n",
    "\n",
    "Display the detected building footprints on an interactive map, colored by area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "geoai.view_vector_interactive(\n",
    "    gdf_filtered,\n",
    "    column=\"area_m2\",\n",
    "    tiles=raster_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Split map comparison\n",
    "\n",
    "Create a side-by-side comparison between the detected buildings and the original imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "geoai.create_split_map(\n",
    "    left_layer=gdf_filtered,\n",
    "    right_layer=raster_path,\n",
    "    left_args={\"style\": {\"color\": \"red\", \"fillOpacity\": 0.2}},\n",
    "    basemap=raster_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Building area statistics\n",
    "\n",
    "Analyze the distribution of building sizes in the detected footprints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gdf_filtered[\"area_m2\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_filtered[\"area_m2\"].hist(bins=50)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.xlabel(\"Area (m\\u00b2)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Building Areas\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Save results\n",
    "\n",
    "Save the final building footprints to a GeoJSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_filtered.to_file(\"whu_buildings_final.geojson\", driver=\"GeoJSON\")\n",
    "print(f\"Saved {len(gdf_filtered)} building footprints to whu_buildings_final.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Advanced: Custom inference parameters\n",
    "\n",
    "You can customize the inference by adjusting the window size, overlap, and batch size. Larger windows capture more context but require more memory. More overlap produces smoother predictions at boundaries but increases processing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example with custom parameters\n",
    "# geoai.timm_segmentation_from_hub(\n",
    "#     input_path=raster_path,\n",
    "#     output_path=\"whu_building_prediction_custom.tif\",\n",
    "#     repo_id=\"giswqs/whu-building-unetplusplus-efficientnet-b4\",\n",
    "#     window_size=512,\n",
    "#     overlap=384,  # More overlap for smoother results\n",
    "#     batch_size=2,  # Reduce if running out of GPU memory\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Loading a pre-trained model** from HuggingFace Hub with a single function call\n",
    "2. **Running building detection** on aerial imagery using sliding-window inference\n",
    "3. **Vectorizing results** into clean building footprint polygons\n",
    "4. **Analyzing buildings** with geometric properties and area statistics\n",
    "5. **Visualizing results** with interactive maps and split-map comparisons\n",
    "\n",
    "### Model Details\n",
    "\n",
    "| Property | Value |\n",
    "|----------|-------|\n",
    "| Architecture | UNet++ |\n",
    "| Encoder | EfficientNet-B4 |\n",
    "| Training Data | WHU Building Dataset |\n",
    "| Resolution | 0.3m aerial imagery |\n",
    "| Input | 3-channel RGB, 512Ã—512 tiles |\n",
    "| Classes | Background (0), Building (1) |\n",
    "| HuggingFace | [giswqs/whu-building-unetplusplus-efficientnet-b4](https://huggingface.co/giswqs/whu-building-unetplusplus-efficientnet-b4) |\n",
    "\n",
    "### References\n",
    "\n",
    "- WHU Building Dataset: Ji, S., Wei, S., & Lu, M. (2019). Fully Convolutional Networks for Multisource Building Identification. *IEEE Transactions on Geoscience and Remote Sensing*, 57(1), 108-120."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
