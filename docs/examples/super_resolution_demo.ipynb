{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Resolution Demo for Geospatial Imagery\n",
    "\n",
    "[![image](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/opengeos/geoai/blob/main/docs/examples/super_resolution_demo.ipynb)\n",
    "\n",
    "This notebook provides a comprehensive demonstration of the super resolution functionality in the `geoai` library. Super resolution is a technique that uses deep learning to enhance the resolution of low-resolution images, creating high-resolution outputs from low-resolution inputs.\n",
    "\n",
    "## What is Super Resolution?\n",
    "\n",
    "Super resolution (SR) is an image processing technique that reconstructs high-resolution images from low-resolution inputs using machine learning algorithms. In geospatial AI, this is particularly valuable for:\n",
    "\n",
    "- **Enhancing satellite imagery**: Improving resolution of older or lower-quality satellite data\n",
    "- **Temporal analysis**: Making historical imagery comparable to modern high-resolution data\n",
    "- **Resource efficiency**: Reducing the need for expensive high-resolution satellite acquisitions\n",
    "- **Environmental monitoring**: Better detection of small features in land cover, vegetation, and urban areas\n",
    "\n",
    "## The geoai Super Resolution Function\n",
    "\n",
    "The `geoai.super_resolution` module provides a `SuperResolutionModel` class that implements state-of-the-art super resolution algorithms:\n",
    "\n",
    "- **ESRGAN**: Enhanced Super-Resolution Generative Adversarial Network - produces highly realistic results\n",
    "- **SRCNN**: Super-Resolution Convolutional Neural Network - faster and more lightweight\n",
    "\n",
    "### Key Parameters\n",
    "\n",
    "- `model_type`: 'esrgan' or 'srcnn'\n",
    "- `upscale_factor`: Scaling factor (2, 4, 8)\n",
    "- `num_channels`: Number of input channels (3 for RGB, 4 for RGB+NIR)\n",
    "- `device`: Computing device ('cuda', 'cpu', 'mps')\n",
    "\n",
    "### Main Methods\n",
    "\n",
    "- `enhance_image()`: Apply super resolution to an image\n",
    "- `train()`: Train the model on custom data\n",
    "- `load_model()`: Load pre-trained weights\n",
    "- `evaluate()`: Calculate PSNR and SSIM metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Package\n",
    "\n",
    "To use the `geoai-py` package, ensure it is installed in your environment. Uncomment the command below if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install geoai-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "import rasterio\n",
    "from rasterio.transform import from_bounds\n",
    "import torch\n",
    "\n",
    "import geoai\n",
    "from geoai.super_resolution import SuperResolutionModel, create_super_resolution_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Sample Data\n",
    "\n",
    "We'll use a sample NAIP (National Agriculture Imagery Program) image for demonstration. This high-resolution aerial imagery will serve as our \"ground truth\" high-resolution image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sample high-resolution NAIP imagery\n",
    "naip_url = (\n",
    "    \"https://huggingface.co/datasets/giswqs/geospatial/resolve/main/naip_test.tif\"\n",
    ")\n",
    "hr_image_path = geoai.download_file(naip_url)\n",
    "\n",
    "print(f\"Downloaded high-resolution image: {hr_image_path}\")\n",
    "geoai.get_raster_info(hr_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Sample Data\n",
    "\n",
    "For demonstration purposes, we'll create a low-resolution version of our high-resolution image by downsampling it. In real-world scenarios, you would start with actual low-resolution imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_low_res_version(hr_path, scale_factor=4, output_path=None):\n",
    "    \"\"\"\n",
    "    Create a low-resolution version of a high-resolution image by downsampling.\n",
    "\n",
    "    Args:\n",
    "        hr_path: Path to high-resolution image\n",
    "        scale_factor: Downsampling factor\n",
    "        output_path: Path to save low-resolution image\n",
    "\n",
    "    Returns:\n",
    "        Path to low-resolution image\n",
    "    \"\"\"\n",
    "    with rasterio.open(hr_path) as src:\n",
    "        # Read RGB bands\n",
    "        if src.count >= 3:\n",
    "            hr_image = src.read([1, 2, 3])\n",
    "        else:\n",
    "            hr_image = src.read(1)\n",
    "            hr_image = np.stack([hr_image, hr_image, hr_image])\n",
    "\n",
    "        meta = src.meta.copy()\n",
    "        transform = src.transform\n",
    "        crs = src.crs\n",
    "\n",
    "        # Downsample using bicubic interpolation\n",
    "        from skimage.transform import resize\n",
    "\n",
    "        lr_image = (\n",
    "            resize(\n",
    "                hr_image.transpose(1, 2, 0),\n",
    "                (hr_image.shape[1] // scale_factor, hr_image.shape[2] // scale_factor),\n",
    "                anti_aliasing=True,\n",
    "                preserve_range=True,\n",
    "            )\n",
    "            .astype(np.uint8)\n",
    "            .transpose(2, 0, 1)\n",
    "        )\n",
    "\n",
    "        # Update metadata for low-resolution image\n",
    "        new_transform = from_bounds(\n",
    "            transform.c,  # left\n",
    "            transform.f - (transform.e * hr_image.shape[1]),  # bottom\n",
    "            transform.c + (transform.a * hr_image.shape[2]),  # right\n",
    "            transform.f,  # top\n",
    "            lr_image.shape[2],\n",
    "            lr_image.shape[1],\n",
    "        )\n",
    "\n",
    "        meta.update(\n",
    "            {\n",
    "                \"height\": lr_image.shape[1],\n",
    "                \"width\": lr_image.shape[2],\n",
    "                \"transform\": new_transform,\n",
    "                \"count\": 3,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if output_path is None:\n",
    "            output_path = hr_path.replace(\".tif\", f\"_lr_x{scale_factor}.tif\")\n",
    "\n",
    "        with rasterio.open(output_path, \"w\", **meta) as dst:\n",
    "            dst.write(lr_image)\n",
    "\n",
    "        return output_path\n",
    "\n",
    "\n",
    "# Create low-resolution version\n",
    "lr_image_path = create_low_res_version(hr_image_path, scale_factor=4)\n",
    "print(f\"Created low-resolution image: {lr_image_path}\")\n",
    "geoai.get_raster_info(lr_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Original vs Low-Resolution Images\n",
    "\n",
    "Let's compare the high-resolution original with our artificially created low-resolution version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display images\n",
    "def load_rgb_image(path):\n",
    "    with rasterio.open(path) as src:\n",
    "        if src.count >= 3:\n",
    "            img = src.read([1, 2, 3])\n",
    "        else:\n",
    "            img = src.read(1)\n",
    "            img = np.stack([img, img, img])\n",
    "        return img.transpose(1, 2, 0)\n",
    "\n",
    "\n",
    "hr_img = load_rgb_image(hr_image_path)\n",
    "lr_img = load_rgb_image(lr_image_path)\n",
    "\n",
    "# Display comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "axes[0].imshow(hr_img)\n",
    "axes[0].set_title(f\"High-Resolution\\n{hr_img.shape}\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(lr_img)\n",
    "axes[1].set_title(f\"Low-Resolution\\n{lr_img.shape}\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    f\"Resolution improvement needed: {hr_img.shape[0] // lr_img.shape[0]}x in each dimension\"\n",
    ")\n",
    "print(f\"Total pixel increase: {(hr_img.shape[0] // lr_img.shape[0]) ** 2}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Super Resolution Model\n",
    "\n",
    "Now we'll create a super resolution model. For demonstration, we'll use the ESRGAN model with 4x upscaling. Note that without pre-trained weights, the model will produce results similar to bicubic interpolation, but the framework is ready for trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ESRGAN model for 4x super resolution\n",
    "sr_model = create_super_resolution_model(\n",
    "    model_type=\"esrgan\",\n",
    "    upscale_factor=4,\n",
    "    num_channels=3,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "\n",
    "print(f\"Created {sr_model.model_type} model with {sr_model.upscale_factor}x upscaling\")\n",
    "print(f\"Using device: {sr_model.device}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in sr_model.model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Super Resolution\n",
    "\n",
    "Now we'll apply the super resolution model to enhance our low-resolution image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply super resolution\n",
    "sr_output_path = lr_image_path.replace(\"_lr_x4.tif\", \"_sr_esrgan.tif\")\n",
    "\n",
    "print(\"Applying super resolution...\")\n",
    "sr_path = sr_model.enhance_image(\n",
    "    input_path=lr_image_path,\n",
    "    output_path=sr_output_path,\n",
    "    tile_size=256,  # Process in tiles for large images\n",
    "    overlap=32,\n",
    ")\n",
    "\n",
    "print(f\"Super-resolved image saved to: {sr_path}\")\n",
    "geoai.get_raster_info(sr_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Results\n",
    "\n",
    "Let's compare the original low-resolution image, the super-resolved output, and the ground truth high-resolution image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load super-resolved image\n",
    "sr_img = load_rgb_image(sr_path)\n",
    "\n",
    "# Display comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# Low-resolution (bicubic upsampled for comparison)\n",
    "lr_upsampled = (\n",
    "    np.array(plt.imread(lr_image_path.replace(\".tif\", \"_lr_x4.tif\")))\n",
    "    if os.path.exists(lr_image_path.replace(\".tif\", \"_lr_x4.tif\"))\n",
    "    else lr_img\n",
    ")\n",
    "if lr_upsampled.shape != hr_img.shape:\n",
    "    from skimage.transform import resize\n",
    "\n",
    "    lr_upsampled = resize(lr_img, hr_img.shape[:2], preserve_range=True).astype(\n",
    "        np.uint8\n",
    "    )\n",
    "\n",
    "axes[0].imshow(lr_upsampled)\n",
    "axes[0].set_title(\"Low-Res + Bicubic Upsampling\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(sr_img)\n",
    "axes[1].set_title(\"Super Resolution (ESRGAN)\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "axes[2].imshow(hr_img)\n",
    "axes[2].set_title(\"Ground Truth (High-Res)\")\n",
    "axes[2].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative Evaluation\n",
    "\n",
    "Let's calculate quantitative metrics to evaluate the super resolution performance. We'll compare PSNR (Peak Signal-to-Noise Ratio) and SSIM (Structural Similarity Index) between the different methods and the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(pred, target, data_range=255.0):\n",
    "    \"\"\"Calculate PSNR and SSIM metrics.\"\"\"\n",
    "    # Ensure same shape\n",
    "    if pred.shape != target.shape:\n",
    "        from skimage.transform import resize\n",
    "\n",
    "        pred = resize(pred, target.shape, preserve_range=True)\n",
    "\n",
    "    psnr = peak_signal_noise_ratio(target, pred, data_range=data_range)\n",
    "    ssim = structural_similarity(target, pred, data_range=data_range, channel_axis=2)\n",
    "\n",
    "    return psnr, ssim\n",
    "\n",
    "\n",
    "# Calculate metrics\n",
    "psnr_bicubic, ssim_bicubic = calculate_metrics(\n",
    "    lr_upsampled.astype(float), hr_img.astype(float)\n",
    ")\n",
    "psnr_sr, ssim_sr = calculate_metrics(sr_img.astype(float), hr_img.astype(float))\n",
    "\n",
    "print(f\"Bicubic Upsampling - PSNR: {psnr_bicubic:.2f} dB, SSIM: {ssim_bicubic:.4f}\")\n",
    "print(f\"Super Resolution   - PSNR: {psnr_sr:.2f} dB, SSIM: {ssim_sr:.4f}\")\n",
    "print(\n",
    "    f\"Improvement        - PSNR: {psnr_sr - psnr_bicubic:.2f} dB, SSIM: {ssim_sr - ssim_bicubic:.4f}\"\n",
    ")\n",
    "\n",
    "# Create metrics visualization\n",
    "methods = [\"Bicubic\", \"Super Resolution\"]\n",
    "psnr_values = [psnr_bicubic, psnr_sr]\n",
    "ssim_values = [ssim_bicubic, ssim_sr]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].bar(methods, psnr_values, color=[\"skyblue\", \"lightgreen\"])\n",
    "axes[0].set_title(\"PSNR Comparison\")\n",
    "axes[0].set_ylabel(\"PSNR (dB)\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].bar(methods, ssim_values, color=[\"skyblue\", \"lightgreen\"])\n",
    "axes[1].set_title(\"SSIM Comparison\")\n",
    "axes[1].set_ylabel(\"SSIM\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Different Model Types\n",
    "\n",
    "Let's compare the performance of different super resolution models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SRCNN model for comparison\n",
    "srcnn_model = create_super_resolution_model(\n",
    "    model_type=\"srcnn\",\n",
    "    upscale_factor=4,\n",
    "    num_channels=3,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "\n",
    "# Apply SRCNN\n",
    "srcnn_output_path = lr_image_path.replace(\"_lr_x4.tif\", \"_sr_srcnn.tif\")\n",
    "srcnn_path = srcnn_model.enhance_image(\n",
    "    input_path=lr_image_path, output_path=srcnn_output_path\n",
    ")\n",
    "\n",
    "# Load and evaluate\n",
    "srcnn_img = load_rgb_image(srcnn_path)\n",
    "psnr_srcnn, ssim_srcnn = calculate_metrics(\n",
    "    srcnn_img.astype(float), hr_img.astype(float)\n",
    ")\n",
    "\n",
    "print(f\"SRCNN Results - PSNR: {psnr_srcnn:.2f} dB, SSIM: {ssim_srcnn:.4f}\")\n",
    "\n",
    "# Compare all methods\n",
    "methods = [\"Bicubic\", \"SRCNN\", \"ESRGAN\"]\n",
    "psnr_all = [psnr_bicubic, psnr_srcnn, psnr_sr]\n",
    "ssim_all = [ssim_bicubic, ssim_srcnn, ssim_sr]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0].bar(methods, psnr_all, color=[\"skyblue\", \"orange\", \"lightgreen\"])\n",
    "axes[0].set_title(\"PSNR Comparison - All Methods\")\n",
    "axes[0].set_ylabel(\"PSNR (dB)\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].bar(methods, ssim_all, color=[\"skyblue\", \"orange\", \"lightgreen\"])\n",
    "axes[1].set_title(\"SSIM Comparison - All Methods\")\n",
    "axes[1].set_ylabel(\"SSIM\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling and Edge Cases\n",
    "\n",
    "Let's demonstrate how the super resolution function handles various edge cases and potential errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with invalid inputs\n",
    "try:\n",
    "    # Invalid model type\n",
    "    invalid_model = create_super_resolution_model(model_type=\"invalid\")\n",
    "except ValueError as e:\n",
    "    print(f\"Expected error for invalid model type: {e}\")\n",
    "\n",
    "try:\n",
    "    # Non-existent file\n",
    "    sr_model.enhance_image(\"non_existent.tif\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Expected error for missing file: {e}\")\n",
    "\n",
    "# Test with different upscale factors\n",
    "for factor in [2, 4, 8]:\n",
    "    try:\n",
    "        test_model = create_super_resolution_model(\n",
    "            model_type=\"srcnn\", upscale_factor=factor, num_channels=3\n",
    "        )\n",
    "        print(f\"Successfully created model with {factor}x upscaling\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {factor}x upscaling: {e}\")\n",
    "\n",
    "# Test memory constraints (small tile size)\n",
    "large_sr_path = sr_model.enhance_image(\n",
    "    input_path=lr_image_path,\n",
    "    tile_size=128,  # Smaller tiles for memory efficiency\n",
    "    overlap=16,\n",
    ")\n",
    "print(f\"Processed with small tiles: {large_sr_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Custom Model (Optional)\n",
    "\n",
    "For demonstration purposes, we'll show how to train a super resolution model. Note that training requires significant computational resources and time, so this is commented out by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data directory\n",
    "train_dir = \"sr_training_data\"\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "\n",
    "# Copy our high-res image to training directory\n",
    "import shutil\n",
    "\n",
    "shutil.copy(hr_image_path, os.path.join(train_dir, \"sample_hr.tif\"))\n",
    "\n",
    "print(f\"Training data prepared in: {train_dir}\")\n",
    "\n",
    "# Training code (commented out - requires significant compute)\n",
    "\"\"\"\n",
    "# Create training model\n",
    "train_model = create_super_resolution_model(\n",
    "    model_type='srcnn',  # Faster training than ESRGAN\n",
    "    upscale_factor=4,\n",
    "    num_channels=3\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = train_model.train(\n",
    "    train_dir=train_dir,\n",
    "    epochs=50,  # Increase for better results\n",
    "    batch_size=8,\n",
    "    learning_rate=1e-4,\n",
    "    save_path='trained_sr_model.pth'\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "if 'val_loss' in history:\n",
    "    plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training History')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "print(\"Training code is commented out. Uncomment to train a custom model.\")\n",
    "print(\"Training typically requires hours of GPU compute for good results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the comprehensive usage of the super resolution functionality in the `geoai` library. Here's a summary of what we covered:\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Super Resolution in Geospatial AI**: SR can significantly enhance the resolution of satellite and aerial imagery, enabling better analysis of land cover, urban features, and environmental changes.\n",
    "\n",
    "2. **Model Types**: \n",
    "   - **ESRGAN**: Better image quality, more computationally intensive\n",
    "   - **SRCNN**: Faster inference, good for real-time applications\n",
    "\n",
    "3. **Practical Usage**:\n",
    "   - Easy model creation with `create_super_resolution_model()`\n",
    "   - Flexible enhancement with `enhance_image()` method\n",
    "   - Support for large images through tiled processing\n",
    "   - Multiple upscale factors (2x, 4x, 8x)\n",
    "\n",
    "4. **Evaluation Metrics**:\n",
    "   - **PSNR**: Measures pixel-level accuracy\n",
    "   - **SSIM**: Assesses structural similarity\n",
    "   - Higher values indicate better performance\n",
    "\n",
    "### Applications in Geospatial Analysis\n",
    "\n",
    "- **Land Cover Classification**: Improved resolution leads to better classification accuracy\n",
    "- **Urban Planning**: Enhanced detail for building and infrastructure analysis\n",
    "- **Environmental Monitoring**: Better detection of small changes in vegetation and water bodies\n",
    "- **Historical Data Enhancement**: Making older imagery comparable to modern high-resolution data\n",
    "\n",
    "### Tips for Real-World Usage\n",
    "\n",
    "1. **Model Selection**: Use ESRGAN for quality-critical applications, SRCNN for speed\n",
    "2. **Training Data**: More diverse training data leads to better generalization\n",
    "3. **Hardware**: GPU acceleration is recommended for large images\n",
    "4. **Evaluation**: Always evaluate with domain-specific metrics, not just PSNR/SSIM\n",
    "5. **Preprocessing**: Consider atmospheric correction and radiometric normalization\n",
    "6. **Post-processing**: Apply super resolution before, not after, geometric corrections\n",
    "\n",
    "### Limitations and Considerations\n",
    "\n",
    "- **Training Requirements**: Models need extensive training for optimal performance\n",
    "- **Computational Cost**: High-resolution outputs require significant compute resources\n",
    "- **Artifacts**: Untrained models may introduce artifacts\n",
    "- **Generalization**: Models trained on specific regions may not generalize well to others\n",
    "\n",
    "For production use, consider training custom models on your specific data domain for best results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
