{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Using Hugging Face Auto Modules with GeoAI\n",
    "\n",
    "[![image](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/opengeos/geoai/blob/main/docs/examples/AutoModel.ipynb)\n",
    "\n",
    "This notebook demonstrates how to use the `AutoGeoModel` and related functions from GeoAI for various geospatial machine learning tasks using Hugging Face models.\n",
    "\n",
    "## Supported Tasks\n",
    "\n",
    "- **Zero-shot Object Detection**: Detect objects using text prompts (e.g., Grounding DINO)\n",
    "- **Semantic Segmentation**: Pixel-level classification (e.g., SegFormer)\n",
    "- **Image Classification**: Classify entire images (e.g., ViT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U geoai-py transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geoai import download_file\n",
    "from geoai.auto import (\n",
    "    AutoGeoModel,\n",
    "    semantic_segmentation,\n",
    "    image_classification,\n",
    "    object_detection,\n",
    "    get_hf_tasks,\n",
    "    get_hf_model_config,\n",
    "    show_image,\n",
    "    show_detections,\n",
    "    show_segmentation,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Download Sample Data\n",
    "\n",
    "Download sample aerial imagery for the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://huggingface.co/datasets/giswqs/geospatial/resolve/main/aerial.tif\"\n",
    "image_path = download_file(image_url, \"aerial.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Display the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(image_path, title=\"Aerial Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 1. Zero-Shot Object Detection with Grounding DINO\n",
    "\n",
    "Grounding DINO allows you to detect objects using natural language text prompts. This is useful when you need to detect custom objects in aerial/satellite imagery without training a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = object_detection(\n",
    "    image_path,\n",
    "    labels=[\"building\", \"tree\", \"car\", \"road\"],\n",
    "    box_threshold=0.25,\n",
    "    text_threshold=0.25,\n",
    ")\n",
    "\n",
    "print(f\"Detected {len(result.get('boxes', []))} objects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Visualize Detection Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_detections(\n",
    "    image_path,\n",
    "    result,\n",
    "    title=\"Zero-Shot Object Detection with Grounding DINO\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Save Detection Results to GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = object_detection(\n",
    "    image_path,\n",
    "    labels=[\"building\", \"tree\", \"car\"],\n",
    "    box_threshold=0.25,\n",
    "    output_vector_path=\"detections.geojson\",\n",
    ")\n",
    "\n",
    "if \"geodataframe\" in result:\n",
    "    print(\"Detection results saved to detections.geojson\")\n",
    "    print(result[\"geodataframe\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Using AutoGeoModel Directly\n",
    "\n",
    "For more control, you can use `AutoGeoModel` directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoGeoModel.from_pretrained(\n",
    "    \"IDEA-Research/grounding-dino-base\",\n",
    "    task=\"zero-shot-object-detection\",\n",
    ")\n",
    "\n",
    "result = model.predict(\n",
    "    image_path,\n",
    "    text=\"a building. a tree. a car.\",\n",
    "    box_threshold=0.25,\n",
    "    text_threshold=0.25,\n",
    ")\n",
    "\n",
    "print(\"Detection Results:\")\n",
    "if \"boxes\" in result:\n",
    "    for box, score, label in zip(result[\"boxes\"], result[\"scores\"], result[\"labels\"]):\n",
    "        print(f\"  - {label}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## 2. Semantic Segmentation with SegFormer\n",
    "\n",
    "Semantic segmentation assigns a class label to each pixel in the image. This is useful for land cover classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_result = semantic_segmentation(\n",
    "    image_path,\n",
    "    output_path=\"segmentation_output.tif\",\n",
    "    model_name=\"nvidia/segformer-b0-finetuned-ade-512-512\",\n",
    ")\n",
    "\n",
    "mask = seg_result.get(\"mask\", seg_result.get(\"output\"))\n",
    "print(f\"Segmentation mask shape: {mask.shape}\")\n",
    "print(f\"Unique classes: {len(set(mask.flatten()))}\")\n",
    "print(f\"Output saved to: segmentation_output.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Visualize Segmentation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_segmentation(\n",
    "    image_path,\n",
    "    mask,\n",
    "    title=\"Semantic Segmentation (SegFormer)\",\n",
    "    alpha=0.6,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Vectorize Segmentation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_result = semantic_segmentation(\n",
    "    image_path,\n",
    "    output_path=\"segmentation_output.tif\",\n",
    "    output_vector_path=\"segmentation.geojson\",\n",
    "    model_name=\"nvidia/segformer-b0-finetuned-ade-512-512\",\n",
    "    min_object_area=50,\n",
    "    simplify_tolerance=1.0,\n",
    ")\n",
    "\n",
    "if \"geodataframe\" in seg_result:\n",
    "    print(\"Vectorized segmentation saved to segmentation.geojson\")\n",
    "    print(f\"Number of polygons: {len(seg_result['geodataframe'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## 3. Image Classification with ViT\n",
    "\n",
    "Classify entire images into categories using Vision Transformer (ViT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoConfig\n",
    "\n",
    "cls_result = image_classification(\n",
    "    image_path,\n",
    "    model_name=\"google/vit-base-patch16-224\",\n",
    ")\n",
    "\n",
    "# Get class labels from model config\n",
    "config = AutoConfig.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "id2label = config.id2label\n",
    "\n",
    "print(f\"Predicted class index: {cls_result.get('class')}\")\n",
    "if \"probabilities\" in cls_result and cls_result[\"probabilities\"] is not None:\n",
    "    probs = cls_result[\"probabilities\"]\n",
    "    top_indices = np.argsort(probs)[-5:][::-1]\n",
    "    print(\"\\nTop 5 predictions:\")\n",
    "    for idx in top_indices:\n",
    "        label = id2label.get(idx, f\"Class {idx}\")\n",
    "        print(f\"  {label}: {probs[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## 5. List Available Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = get_hf_tasks()\n",
    "print(\"Supported tasks:\")\n",
    "for task in tasks:\n",
    "    print(f\"  - {task}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## 6. Get Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_hf_model_config(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
    "print(f\"Model type: {config.get('model_type')}\")\n",
    "print(f\"Number of labels: {config.get('num_labels')}\")\n",
    "print(f\"Hidden sizes: {config.get('hidden_sizes')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "files_to_remove = [\n",
    "    \"aerial.tif\",\n",
    "    \"segmentation_output.tif\",\n",
    "    \"segmentation.geojson\",\n",
    "    \"detections.geojson\",\n",
    "]\n",
    "\n",
    "for f in files_to_remove:\n",
    "    if os.path.exists(f):\n",
    "        os.remove(f)\n",
    "        print(f\"Removed {f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
