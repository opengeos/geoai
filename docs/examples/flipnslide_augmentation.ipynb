{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flip-n-Slide Data Augmentation for Geospatial Tiling\n\n[![image](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/opengeos/geoai/blob/main/docs/examples/flipnslide_augmentation.ipynb)\n\nThis notebook demonstrates the **Flip-n-Slide** tiling strategy for geospatial imagery, based on the paper:\n\n> Abrahams, E., Snow, T., Siegfried, M. R., & Perez, F. (2024). *A Concise Tiling Strategy for Preserving Spatial Context in Earth Observation Imagery*. ML4RS Workshop @ ICLR 2024 (Best Short Paper). [arXiv:2404.10927](https://doi.org/10.48550/arXiv.2404.10927)\n\n## Overview\n\nTraditional grid tiling discards spatial context at tile boundaries. Flip-n-Slide generates **overlapping tiles with diverse augmentations** that:\n\n- Preserve spatial context across tile boundaries\n- Eliminate redundant pixel representations through rotations and flips\n- Produce more diverse training data without external augmentation libraries\n\nThe algorithm creates two sets of tiles:\n\n1. **Standard overlapping tiles** (half-stride) with rotational augmentations (identity, 90\u00b0, 180\u00b0, 270\u00b0)\n2. **Inner offset tiles** (25%/75% positions) with flip + rotation augmentations (h-flip, v-flip, 90\u00b0+h-flip, 90\u00b0+v-flip)\n\nGitHub Issue: [#88](https://github.com/opengeos/geoai/issues/88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U geoai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\nimport geoai\nimport numpy as np\nimport rasterio\nimport matplotlib.pyplot as plt\nfrom pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download sample data\n\nWe'll use NAIP aerial imagery with building footprints for this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_url = (\n    \"https://huggingface.co/datasets/giswqs/geospatial/resolve/main/naip_rgb_train.tif\"\n)\nvector_url = \"https://huggingface.co/datasets/giswqs/geospatial/resolve/main/naip_train_buildings.geojson\"\n\nsample_image = geoai.download_file(raster_url)\nsample_vector = geoai.download_file(vector_url)\n\nprint(f\"Downloaded image: {sample_image}\")\nprint(f\"Downloaded labels: {sample_vector}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoai.get_raster_info(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoai.view_vector_interactive(sample_vector, tiles=sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flip-n-Slide with numpy arrays\n\nThe `flipnslide_augmentation` function works directly on numpy arrays of shape `(channels, height, width)`. It returns the tiles and a list of augmentation indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the raster as a numpy array\nwith rasterio.open(sample_image) as src:\n    image_data = src.read()\n\nprint(f\"Image shape: {image_data.shape}\")\nprint(f\"Image dtype: {image_data.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Flip-n-Slide augmentation\ntiles, aug_indices = geoai.flipnslide_augmentation(image_data, tile_size=256)\n\nprint(f\"Number of tiles: {tiles.shape[0]}\")\nprint(f\"Tile shape: {tiles.shape[1:]}\")\nprint(f\"Augmentation types used: {sorted(set(aug_indices))}\\n\")\n\n# Count each augmentation type\naug_names = {\n    0: \"Identity\",\n    1: \"180\u00b0 rotation\",\n    2: \"90\u00b0 rotation\",\n    3: \"270\u00b0 rotation\",\n    4: \"Horizontal flip\",\n    5: \"Vertical flip\",\n    6: \"90\u00b0 + H-flip\",\n    7: \"90\u00b0 + V-flip\",\n}\nfrom collections import Counter\ncounts = Counter(aug_indices)\nfor idx in sorted(counts):\n    print(f\"  {aug_names.get(idx, f'Type {idx}')}: {counts[idx]} tiles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize augmented tiles\n\nLet's display a grid of tiles grouped by augmentation type to see the diversity of transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\nfig.suptitle(\"Flip-n-Slide Augmentation Types\", fontsize=16, fontweight=\"bold\")\n\nfor aug_type in range(8):\n    row, col = divmod(aug_type, 4)\n    ax = axes[row, col]\n\n    # Find first tile with this augmentation type\n    matching = [i for i, a in enumerate(aug_indices) if a == aug_type]\n    if matching:\n        tile = tiles[matching[0]]\n        # Convert CHW -> HWC for display\n        tile_rgb = np.transpose(tile[:3], (1, 2, 0))\n        # Normalize to 0-1 for display\n        tile_rgb = tile_rgb.astype(float)\n        if tile_rgb.max() > 1:\n            tile_rgb = tile_rgb / 255.0\n        tile_rgb = np.clip(tile_rgb, 0, 1)\n        ax.imshow(tile_rgb)\n    ax.set_title(aug_names.get(aug_type, f\"Type {aug_type}\"), fontsize=11)\n    ax.axis(\"off\")\n\nplt.tight_layout()\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch tensor output\n\nThe function also supports outputting tiles as PyTorch tensors, useful for direct integration with training pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_tensor, aug_indices_tensor = geoai.flipnslide_augmentation(\n    image_data, tile_size=256, output_format=\"torch\"\n)\n\nprint(f\"Type: {type(tiles_tensor)}\")\nprint(f\"Shape: {tiles_tensor.shape}\")\nprint(f\"Dtype: {tiles_tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Flip-n-Slide tiles as GeoTIFFs\n\nThe `export_flipnslide_tiles` function is a geospatial-aware wrapper that preserves CRS and geotransform information for each tile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_flipnslide = \"flipnslide_demo/flipnslide_tiles\"\n\nstats = geoai.export_flipnslide_tiles(\n    sample_image,\n    output_flipnslide,\n    tile_size=256,\n)\n\nprint(f\"\\nTotal tiles: {stats['total_tiles']}\")\nprint(f\"Tile size: {stats['tile_size']}px\")\nprint(f\"Output folder: {stats['output_folder']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export with label/mask data\n\nWhen a label raster is provided, matching mask tiles are generated with identical augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_with_labels = \"flipnslide_demo/flipnslide_tiles_with_labels\"\n\n# First create a raster mask from the vector labels\nfrom geoai.utils import export_geotiff_tiles\n\n# Use export_geotiff_tiles with flipnslide strategy and vector class data\nstats_labels = geoai.export_geotiff_tiles(\n    sample_image,\n    output_with_labels,\n    in_class_data=sample_vector,\n    tile_size=256,\n    tiling_strategy=\"flipnslide\",\n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare grid tiling vs Flip-n-Slide\n\nLet's compare the number of tiles generated by standard grid tiling versus the Flip-n-Slide strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard grid tiling (no overlap)\noutput_grid = \"flipnslide_demo/grid_tiles\"\ngeoai.export_geotiff_tiles(\n    sample_image,\n    output_grid,\n    tile_size=256,\n    stride=256,\n    tiling_strategy=\"grid\",\n)\ngrid_tiles = list(Path(output_grid, \"images\").glob(\"*.tif\"))\n\n# Standard grid tiling with half-stride overlap\noutput_overlap = \"flipnslide_demo/overlap_tiles\"\ngeoai.export_geotiff_tiles(\n    sample_image,\n    output_overlap,\n    tile_size=256,\n    stride=128,\n    tiling_strategy=\"grid\",\n)\noverlap_tiles = list(Path(output_overlap, \"images\").glob(\"*.tif\"))\n\n# Flip-n-Slide\nfns_tiles = list(Path(output_flipnslide, \"images\").glob(\"*.tif\"))\n\nprint(\"Tiling Strategy Comparison:\")\nprint(f\"  Grid (stride=256):       {len(grid_tiles)} tiles\")\nprint(f\"  Grid (stride=128):       {len(overlap_tiles)} tiles\")\nprint(f\"  Flip-n-Slide:            {len(fns_tiles)} tiles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using tiling_strategy parameter\n\nThe existing `export_geotiff_tiles` function now supports a `tiling_strategy` parameter to switch between standard grid tiling and Flip-n-Slide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Flip-n-Slide via the tiling_strategy parameter\noutput_strategy = \"flipnslide_demo/strategy_demo\"\n\ngeoai.export_geotiff_tiles(\n    sample_image,\n    output_strategy,\n    tile_size=256,\n    tiling_strategy=\"flipnslide\",  # Use Flip-n-Slide instead of grid\n)\n\nstrategy_tiles = list(Path(output_strategy, \"images\").glob(\"*.tif\"))\nprint(f\"Tiles generated with tiling_strategy='flipnslide': {len(strategy_tiles)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize tile spatial distribution\n\nLet's visualize a few exported GeoTIFF tiles to confirm they have proper spatial metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_dir = Path(output_flipnslide, \"images\")\ntile_files = sorted(tile_dir.glob(\"*.tif\"))[:6]\n\nfig, axes = plt.subplots(1, min(6, len(tile_files)), figsize=(18, 3.5))\nif len(tile_files) == 1:\n    axes = [axes]\n\nfor ax, tile_path in zip(axes, tile_files):\n    with rasterio.open(tile_path) as src:\n        tile = src.read()\n        crs = src.crs\n\n    tile_rgb = np.transpose(tile[:3], (1, 2, 0)).astype(float)\n    if tile_rgb.max() > 1:\n        tile_rgb = tile_rgb / 255.0\n    tile_rgb = np.clip(tile_rgb, 0, 1)\n    ax.imshow(tile_rgb)\n    ax.set_title(tile_path.name, fontsize=9)\n    ax.axis(\"off\")\n\nplt.suptitle(f\"Sample Flip-n-Slide tiles (CRS: {crs})\", fontsize=13)\nplt.tight_layout()\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\nif os.path.exists(\"flipnslide_demo\"):\n    shutil.rmtree(\"flipnslide_demo\")\n    print(\"Cleaned up demo files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n\nThis notebook demonstrated:\n\n1. **`flipnslide_augmentation()`** \u2014 Apply Flip-n-Slide directly to numpy arrays or PyTorch tensors\n2. **`export_flipnslide_tiles()`** \u2014 Export georeferenced tiles with CRS and geotransform preserved\n3. **`tiling_strategy=\"flipnslide\"`** \u2014 Use Flip-n-Slide via the existing `export_geotiff_tiles` function\n\n### Benefits of Flip-n-Slide\n\n- **Spatial context preservation**: Overlapping tiles maintain context across boundaries\n- **Built-in augmentation diversity**: 8 different augmentation types without external libraries\n- **No redundancy**: Each pixel appears in multiple tiles but with different transformations\n- **Geospatial-aware**: Preserves CRS and geotransform metadata for each tile\n\n### Reference\n\nAbrahams, E., Snow, T., Siegfried, M. R., & Perez, F. (2024). *A Concise Tiling Strategy for Preserving Spatial Context in Earth Observation Imagery*. ML4RS Workshop @ ICLR 2024. [arXiv:2404.10927](https://doi.org/10.48550/arXiv.2404.10927)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}