{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geospatial Embedding Datasets with TorchGeo\n",
    "\n",
    "[![image](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/opengeos/geoai/blob/main/docs/examples/torchgeo_embeddings.ipynb)\n",
    "\n",
    "## Overview\n",
    "\n",
    "[TorchGeo v0.9.0](https://github.com/torchgeo/torchgeo/releases/tag/v0.9.0) introduces **Earth Embeddings** — pre-computed representations from geospatial foundation models that encode satellite imagery into compact vector representations. These embeddings enable rapid analysis without requiring GPU compute for running foundation models.\n",
    "\n",
    "This notebook demonstrates how to use the `geoai` embeddings module to:\n",
    "\n",
    "1. **Browse** available embedding datasets\n",
    "2. **Load** patch-based embedding datasets (Clay Foundation Model)\n",
    "3. **Visualize** high-dimensional embeddings using PCA\n",
    "4. **Cluster** embeddings to discover spatial patterns\n",
    "5. **Search** for similar locations using cosine similarity\n",
    "6. **Classify** land use types using lightweight classifiers on embeddings\n",
    "\n",
    "### Embedding Dataset Types\n",
    "\n",
    "| Type | Format | Examples | Use Case |\n",
    "| :--- | :----- | :------- | :------- |\n",
    "| **Patch-based** | GeoParquet | Clay, Major TOM, Earth Index | Global-scale analysis, classification |\n",
    "| **Pixel-based** | GeoTIFF | Google Satellite, Tessera, Presto | High-resolution mapping, change detection |\n",
    "\n",
    "## Install Package\n",
    "\n",
    "Uncomment the command below if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install geoai-py scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from huggingface_hub import HfApi, hf_hub_download\n",
    "\n",
    "import geoai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Browse Available Embedding Datasets\n",
    "\n",
    "The `geoai` package provides a registry of all embedding datasets available in TorchGeo v0.9.0. Use `list_embedding_datasets()` to see what's available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all embedding datasets\n",
    "df = geoai.list_embedding_datasets(verbose=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by type: patch-based datasets\n",
    "geoai.list_embedding_datasets(kind=\"patch\", verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by type: pixel-based datasets\n",
    "geoai.list_embedding_datasets(kind=\"pixel\", verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed info about a specific dataset\n",
    "info = geoai.get_embedding_info(\"google_satellite\")\n",
    "for key, value in info.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Clay Embeddings (SF Bay Area)\n",
    "\n",
    "We'll use Clay Foundation Model embeddings for the San Francisco Bay Area from [HuggingFace](https://huggingface.co/datasets/made-with-clay/classify-embeddings-sf-baseball-marinas). This dataset contains 768-dimensional embeddings computed from NAIP aerial imagery across 20 tiles, along with labeled locations for baseball fields (class 0) and marinas (class 1).\n",
    "\n",
    "### Download all embedding tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = \"made-with-clay/classify-embeddings-sf-baseball-marinas\"\n",
    "\n",
    "# List all embedding GeoParquet files\n",
    "api = HfApi()\n",
    "embedding_files = [\n",
    "    f.path\n",
    "    for f in api.list_repo_tree(repo_id, repo_type=\"dataset\")\n",
    "    if f.path.endswith(\".gpq\")\n",
    "]\n",
    "print(f\"Found {len(embedding_files)} embedding tiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all tiles and concatenate into a single GeoDataFrame\n",
    "all_gdfs = []\n",
    "for f in embedding_files:\n",
    "    path = hf_hub_download(repo_id, f, repo_type=\"dataset\")\n",
    "    gdf = gpd.read_parquet(path)\n",
    "    all_gdfs.append(gdf)\n",
    "\n",
    "embeddings_gdf = pd.concat(all_gdfs, ignore_index=True)\n",
    "embeddings_gdf = gpd.GeoDataFrame(\n",
    "    embeddings_gdf, geometry=\"geometry\", crs=all_gdfs[0].crs\n",
    ")\n",
    "print(f\"Combined: {len(embeddings_gdf)} patches\")\n",
    "print(f\"Bounds: {embeddings_gdf.total_bounds}\")\n",
    "print(f\"Embedding dimension: {len(embeddings_gdf.iloc[0]['embeddings'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the labeled locations (baseball fields and marinas)\n",
    "labels_file = hf_hub_download(repo_id, \"baseball.geojson\", repo_type=\"dataset\")\n",
    "labels_gdf = gpd.read_file(labels_file)\n",
    "print(f\"Labeled locations: {len(labels_gdf)}\")\n",
    "print(f\"Class distribution:\")\n",
    "print(labels_gdf[\"class\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract embedding vectors\n",
    "\n",
    "Convert the embedding column to a NumPy array and extract coordinates for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings, coordinates from the GeoParquet\n",
    "embeddings = np.stack(embeddings_gdf[\"embeddings\"].values)\n",
    "centroids = embeddings_gdf.geometry.centroid\n",
    "coords_x = centroids.x.values\n",
    "coords_y = centroids.y.values\n",
    "\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"X range: [{coords_x.min():.4f}, {coords_x.max():.4f}]\")\n",
    "print(f\"Y range: [{coords_y.min():.4f}, {coords_y.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Embeddings\n",
    "\n",
    "### Plot individual embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a few embedding vectors to see their patterns\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 3))\n",
    "for i, ax in enumerate(axes):\n",
    "    idx = i * (len(embeddings) // 3)\n",
    "    ax.plot(embeddings[idx], linewidth=0.5)\n",
    "    ax.set_title(f\"Patch {idx} ({coords_y[idx]:.3f}°N, {coords_x[idx]:.3f}°W)\")\n",
    "    ax.set_xlabel(\"Dimension\")\n",
    "    ax.set_ylabel(\"Value\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA projection of all embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the embedding space using PCA\n",
    "fig = geoai.visualize_embeddings(\n",
    "    embeddings,\n",
    "    method=\"pca\",\n",
    "    figsize=(8, 8),\n",
    "    s=3,\n",
    "    alpha=0.4,\n",
    "    title=\"PCA of Clay Embeddings (SF Bay Area)\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cluster Embeddings\n",
    "\n",
    "Use unsupervised clustering to discover patterns in the embeddings without any labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster the embeddings into groups\n",
    "result = geoai.cluster_embeddings(embeddings, n_clusters=8, method=\"kmeans\")\n",
    "cluster_labels = result[\"labels\"]\n",
    "print(f\"Number of clusters: {result['n_clusters']}\")\n",
    "print(f\"Cluster sizes: {np.bincount(cluster_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clusters in PCA space\n",
    "fig = geoai.visualize_embeddings(\n",
    "    embeddings,\n",
    "    labels=cluster_labels,\n",
    "    method=\"pca\",\n",
    "    figsize=(10, 8),\n",
    "    s=5,\n",
    "    alpha=0.5,\n",
    "    title=\"K-Means Clusters of Clay Embeddings\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map clusters geographically\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "scatter = ax.scatter(\n",
    "    coords_x,\n",
    "    coords_y,\n",
    "    c=cluster_labels,\n",
    "    cmap=\"tab10\",\n",
    "    s=3,\n",
    "    alpha=0.6,\n",
    ")\n",
    "plt.colorbar(scatter, ax=ax, label=\"Cluster\")\n",
    "ax.set_xlabel(\"Longitude\")\n",
    "ax.set_ylabel(\"Latitude\")\n",
    "ax.set_title(\"Geographic Distribution of Embedding Clusters\")\n",
    "ax.set_aspect(\"equal\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Similarity Search\n",
    "\n",
    "Find the most similar locations to a query embedding using cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a query embedding (first patch)\n",
    "query_idx = 0\n",
    "query = embeddings[query_idx]\n",
    "print(f\"Query location: ({coords_y[query_idx]:.4f}°N, {coords_x[query_idx]:.4f}°W)\")\n",
    "\n",
    "# Find top-10 most similar locations\n",
    "results = geoai.embedding_similarity(\n",
    "    query=query, embeddings=embeddings, metric=\"cosine\", top_k=10\n",
    ")\n",
    "\n",
    "print(\"\\nTop 10 most similar locations:\")\n",
    "for rank, (idx, score) in enumerate(\n",
    "    zip(results[\"indices\"], results[\"scores\"]), start=1\n",
    "):\n",
    "    print(\n",
    "        f\"  {rank}. Index {idx}: similarity={score:.4f}, \"\n",
    "        f\"location=({coords_y[idx]:.4f}°N, {coords_x[idx]:.4f}°W)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the query and its nearest neighbors on a map\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Background: all embeddings in gray\n",
    "ax.scatter(coords_x, coords_y, c=\"lightgray\", s=1, alpha=0.3)\n",
    "\n",
    "# Highlight nearest neighbors\n",
    "nn_indices = results[\"indices\"]\n",
    "ax.scatter(\n",
    "    coords_x[nn_indices],\n",
    "    coords_y[nn_indices],\n",
    "    c=\"blue\",\n",
    "    s=50,\n",
    "    marker=\"o\",\n",
    "    label=\"Nearest Neighbors\",\n",
    "    edgecolors=\"black\",\n",
    "    linewidths=0.5,\n",
    ")\n",
    "\n",
    "# Highlight the query point\n",
    "ax.scatter(\n",
    "    coords_x[query_idx],\n",
    "    coords_y[query_idx],\n",
    "    c=\"red\",\n",
    "    s=100,\n",
    "    marker=\"*\",\n",
    "    label=\"Query\",\n",
    "    edgecolors=\"black\",\n",
    "    linewidths=0.5,\n",
    "    zorder=5,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Longitude\")\n",
    "ax.set_ylabel(\"Latitude\")\n",
    "ax.set_title(\"Similarity Search: Query and Nearest Neighbors\")\n",
    "ax.legend()\n",
    "ax.set_aspect(\"equal\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Classification with Embeddings\n",
    "\n",
    "Train a lightweight k-NN classifier on the Clay embeddings using labeled data. The dataset includes labeled locations for baseball fields (class 0) and marinas (class 1) in the San Francisco Bay Area.\n",
    "\n",
    "### Prepare training data\n",
    "\n",
    "We match labeled points to their nearest embedding patches using a spatial join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure both GeoDataFrames use the same CRS\n",
    "if labels_gdf.crs != embeddings_gdf.crs:\n",
    "    labels_gdf = labels_gdf.to_crs(embeddings_gdf.crs)\n",
    "\n",
    "# Spatial join: find which embedding patch each labeled point falls within\n",
    "joined = gpd.sjoin(labels_gdf, embeddings_gdf, how=\"inner\", predicate=\"within\")\n",
    "print(f\"Matched {len(joined)} labeled points to embedding patches\")\n",
    "print(f\"Class distribution: {joined['class'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings and labels for matched points\n",
    "labeled_embeddings = np.stack(\n",
    "    [embeddings_gdf.iloc[idx][\"embeddings\"] for idx in joined[\"index_right\"]]\n",
    ")\n",
    "class_labels = joined[\"class\"].values\n",
    "\n",
    "print(f\"Labeled embeddings shape: {labeled_embeddings.shape}\")\n",
    "print(f\"Labels shape: {class_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    labeled_embeddings,\n",
    "    class_labels,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=class_labels,\n",
    ")\n",
    "print(f\"Train: {X_train.shape[0]} samples\")\n",
    "print(f\"Val:   {X_val.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a k-NN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [\"Baseball Field\", \"Marina\"]\n",
    "\n",
    "# Train using geoai's convenience function\n",
    "result = geoai.train_embedding_classifier(\n",
    "    train_embeddings=X_train,\n",
    "    train_labels=y_train,\n",
    "    val_embeddings=X_val,\n",
    "    val_labels=y_val,\n",
    "    method=\"knn\",\n",
    "    n_neighbors=5,\n",
    "    label_names=label_names,\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain accuracy: {result['train_accuracy']:.2%}\")\n",
    "print(f\"Val accuracy:   {result['val_accuracy']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different classifiers\n",
    "methods = [\"knn\", \"random_forest\", \"logistic_regression\"]\n",
    "results_summary = []\n",
    "\n",
    "for method in methods:\n",
    "    res = geoai.train_embedding_classifier(\n",
    "        train_embeddings=X_train,\n",
    "        train_labels=y_train,\n",
    "        val_embeddings=X_val,\n",
    "        val_labels=y_val,\n",
    "        method=method,\n",
    "        label_names=label_names,\n",
    "        verbose=False,\n",
    "    )\n",
    "    results_summary.append(\n",
    "        {\n",
    "            \"Method\": method,\n",
    "            \"Train Acc\": f\"{res['train_accuracy']:.2%}\",\n",
    "            \"Val Acc\": f\"{res['val_accuracy']:.2%}\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "pd.DataFrame(results_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize classified embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize labeled embeddings in PCA space\n",
    "fig = geoai.visualize_embeddings(\n",
    "    labeled_embeddings,\n",
    "    labels=class_labels,\n",
    "    label_names=label_names,\n",
    "    method=\"pca\",\n",
    "    figsize=(8, 8),\n",
    "    s=30,\n",
    "    alpha=0.8,\n",
    "    title=\"PCA of Labeled Embeddings (Baseball vs Marina)\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparing Embeddings for Change Detection\n",
    "\n",
    "Embedding vectors from different time periods can be compared to detect change. The `compare_embeddings` function computes element-wise similarity between two sets of embeddings.\n",
    "\n",
    "Here we demonstrate the concept by comparing embeddings from different spatial patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare first half vs second half of patches to simulate temporal comparison\n",
    "n = len(embeddings)\n",
    "half = n // 2\n",
    "emb_a = embeddings[:half]\n",
    "emb_b = embeddings[half : half + half]  # same number of samples\n",
    "\n",
    "similarity = geoai.compare_embeddings(emb_a, emb_b, metric=\"cosine\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.hist(similarity, bins=50, edgecolor=\"black\", alpha=0.7)\n",
    "ax.axvline(\n",
    "    similarity.mean(),\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Mean: {similarity.mean():.3f}\",\n",
    ")\n",
    "ax.set_xlabel(\"Cosine Similarity\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Embedding Similarity Distribution\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Using TorchGeo Dataset Classes Directly\n",
    "\n",
    "For more advanced usage, you can use the TorchGeo dataset classes directly through `geoai.load_embedding_dataset()`. This gives you access to all the TorchGeo features like transforms, sampling, and plotting.\n",
    "\n",
    "Note: The TorchGeo `ClayEmbeddings` class expects a `date` or `datetime` column in the GeoParquet file. Some community-contributed embedding files may not include this column. In such cases, load the data with geopandas directly (as shown above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load using geoai's unified interface\n",
    "single_file = hf_hub_download(repo_id, embedding_files[0], repo_type=\"dataset\")\n",
    "ds = geoai.load_embedding_dataset(\"clay\", root=single_file)\n",
    "\n",
    "print(f\"Dataset length: {len(ds)}\")\n",
    "print(f\"Dataset type: {type(ds).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access a sample - may fail if the file lacks a 'datetime' column\n",
    "try:\n",
    "    sample = ds[0]\n",
    "    print(f\"Sample keys: {list(sample.keys())}\")\n",
    "    print(f\"Embedding shape: {sample['embedding'].shape}\")\n",
    "    print(f\"Location: ({sample['y'].item():.4f}°N, {sample['x'].item():.4f}°W)\")\n",
    "\n",
    "    fig = ds.plot(sample)\n",
    "    plt.show()\n",
    "except KeyError as e:\n",
    "    print(\n",
    "        f\"Note: This parquet file is missing the '{e.args[0]}' column \"\n",
    "        f\"expected by TorchGeo's ClayEmbeddings class.\"\n",
    "    )\n",
    "    print(\"For such files, use geopandas directly (as shown above).\")\n",
    "    print(\"The TorchGeo class works best with official Clay data products.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we demonstrated the `geoai` embeddings module which provides a unified interface to TorchGeo v0.9.0's embedding datasets. Key takeaways:\n",
    "\n",
    "- **9 embedding datasets** are available, spanning patch-based and pixel-based formats\n",
    "- **No GPU required** for analysis — embeddings are pre-computed\n",
    "- **Lightweight classifiers** (k-NN, Random Forest) work well on embeddings\n",
    "- **Unsupervised clustering** reveals spatial patterns without labels\n",
    "- **Similarity search** enables content-based spatial retrieval\n",
    "- **Change detection** is possible by comparing embeddings across time periods\n",
    "\n",
    "For pixel-based datasets (Google Satellite Embedding, Tessera, etc.), download GeoTIFF files and use `geoai.load_embedding_dataset()` with the `paths` parameter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 4,
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
